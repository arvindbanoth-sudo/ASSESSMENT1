repo,old_file_path,new_file_path,commit_SHA,parent_SHA,commit_message,diff_myers,diff_hist,Discrepancy,file_type
adk-python,src/google/adk/models/lite_llm.py,src/google/adk/models/lite_llm.py,9a44831a089b59b50e3be202d91f0dc00a30c22b,4e8b944e09c7c86172537469b01f27df04bf2117,Add parallel tool call support for litellm (#172)  Co-authored-by: Hangfei Lin <hangfei@google.com>,"diff --git a/src/google/adk/models/lite_llm.py b/src/google/adk/models/lite_llm.py
index acdaa55..aeb4107 100644
--- a/src/google/adk/models/lite_llm.py
+++ b/src/google/adk/models/lite_llm.py
@@ -136,34 +136,44 @@ def _safe_json_serialize(obj) -> str:
 
 def _content_to_message_param(
     content: types.Content,
-) -> Message:
-  """"""Converts a types.Content to a litellm Message.
+) -> Union[Message, list[Message]]:
+  """"""Converts a types.Content to a litellm Message or list of Messages.
+
+  Handles multipart function responses by returning a list of
+  ChatCompletionToolMessage objects if multiple function_response parts exist.
 
   Args:
     content: The content to convert.
 
   Returns:
-    The litellm Message.
+    A litellm Message, a list of litellm Messages.
   """"""
 
-  if content.parts and content.parts[0].function_response:
-    return ChatCompletionToolMessage(
+  tool_messages = []
+  for part in content.parts:
+    if part.function_response:
+      tool_messages.append(
+          ChatCompletionToolMessage(
               role=""tool"",
-        tool_call_id=content.parts[0].function_response.id,
-        content=_safe_json_serialize(
-            content.parts[0].function_response.response
-        ),
+              tool_call_id=part.function_response.id,
+              content=_safe_json_serialize(part.function_response.response),
+          )
       )
+  if tool_messages:
+    return tool_messages if len(tool_messages) > 1 else tool_messages[0]
 
+  # Handle user or assistant messages
   role = _to_litellm_role(content.role)
+  message_content = _get_content(content.parts) or None
 
   if role == ""user"":
-    return ChatCompletionUserMessage(
-        role=""user"", content=_get_content(content.parts)
-    )
-  else:
-
-    tool_calls = [
+    return ChatCompletionUserMessage(role=""user"", content=message_content)
+  else:  # assistant/model
+    tool_calls = []
+    content_present = False
+    for part in content.parts:
+        if part.function_call:
+            tool_calls.append(
                 ChatCompletionMessageToolCall(
                     type=""function"",
                     id=part.function_call.id,
@@ -172,13 +182,15 @@ def _content_to_message_param(
                         arguments=part.function_call.args,
                     ),
                 )
-        for part in content.parts
-        if part.function_call
-    ]
+            )
+        elif part.text or part.inline_data:
+            content_present = True
+
+    final_content = message_content if content_present else None
 
     return ChatCompletionAssistantMessage(
         role=role,
-        content=_get_content(content.parts) or None,
+        content=final_content,
         tool_calls=tool_calls or None,
     )
 
@@ -437,10 +449,13 @@ def _get_completion_inputs(
   Returns:
     The litellm inputs (message list and tool dictionary).
   """"""
-  messages = [
-      _content_to_message_param(content)
-      for content in llm_request.contents or []
-  ]
+  messages = []
+  for content in llm_request.contents or []:
+    message_param_or_list = _content_to_message_param(content)
+    if isinstance(message_param_or_list, list):
+        messages.extend(message_param_or_list)
+    elif message_param_or_list: # Ensure it's not None before appending
+        messages.append(message_param_or_list)
 
   if llm_request.config.system_instruction:
     messages.insert(
","diff --git a/src/google/adk/models/lite_llm.py b/src/google/adk/models/lite_llm.py
index acdaa55..aeb4107 100644
--- a/src/google/adk/models/lite_llm.py
+++ b/src/google/adk/models/lite_llm.py
@@ -136,34 +136,44 @@ def _safe_json_serialize(obj) -> str:
 
 def _content_to_message_param(
     content: types.Content,
-) -> Message:
-  """"""Converts a types.Content to a litellm Message.
+) -> Union[Message, list[Message]]:
+  """"""Converts a types.Content to a litellm Message or list of Messages.
+
+  Handles multipart function responses by returning a list of
+  ChatCompletionToolMessage objects if multiple function_response parts exist.
 
   Args:
     content: The content to convert.
 
   Returns:
-    The litellm Message.
+    A litellm Message, a list of litellm Messages.
   """"""
 
-  if content.parts and content.parts[0].function_response:
-    return ChatCompletionToolMessage(
+  tool_messages = []
+  for part in content.parts:
+    if part.function_response:
+      tool_messages.append(
+          ChatCompletionToolMessage(
               role=""tool"",
-        tool_call_id=content.parts[0].function_response.id,
-        content=_safe_json_serialize(
-            content.parts[0].function_response.response
-        ),
+              tool_call_id=part.function_response.id,
+              content=_safe_json_serialize(part.function_response.response),
           )
+      )
+  if tool_messages:
+    return tool_messages if len(tool_messages) > 1 else tool_messages[0]
 
+  # Handle user or assistant messages
   role = _to_litellm_role(content.role)
+  message_content = _get_content(content.parts) or None
 
   if role == ""user"":
-    return ChatCompletionUserMessage(
-        role=""user"", content=_get_content(content.parts)
-    )
-  else:
-
-    tool_calls = [
+    return ChatCompletionUserMessage(role=""user"", content=message_content)
+  else:  # assistant/model
+    tool_calls = []
+    content_present = False
+    for part in content.parts:
+        if part.function_call:
+            tool_calls.append(
                 ChatCompletionMessageToolCall(
                     type=""function"",
                     id=part.function_call.id,
@@ -172,13 +182,15 @@ def _content_to_message_param(
                         arguments=part.function_call.args,
                     ),
                 )
-        for part in content.parts
-        if part.function_call
-    ]
+            )
+        elif part.text or part.inline_data:
+            content_present = True
+
+    final_content = message_content if content_present else None
 
     return ChatCompletionAssistantMessage(
         role=role,
-        content=_get_content(content.parts) or None,
+        content=final_content,
         tool_calls=tool_calls or None,
     )
 
@@ -437,10 +449,13 @@ def _get_completion_inputs(
   Returns:
     The litellm inputs (message list and tool dictionary).
   """"""
-  messages = [
-      _content_to_message_param(content)
-      for content in llm_request.contents or []
-  ]
+  messages = []
+  for content in llm_request.contents or []:
+    message_param_or_list = _content_to_message_param(content)
+    if isinstance(message_param_or_list, list):
+        messages.extend(message_param_or_list)
+    elif message_param_or_list: # Ensure it's not None before appending
+        messages.append(message_param_or_list)
 
   if llm_request.config.system_instruction:
     messages.insert(
",Yes,SOURCE
adk-python,,src/google/adk/agents/__init__.py,98278201436cc7f642ede1b22407783e8c155b5e,f92478bd5c542c159e589e3603e70741c3677ab7,Agent Development Kit(ADK)  An easy-to-use and powerful framework to build AI agents.,"diff --git a/src/google/adk/agents/__init__.py b/src/google/adk/agents/__init__.py
new file mode 100644
index 0000000..e1f773c
--- /dev/null
+++ b/src/google/adk/agents/__init__.py
@@ -0,0 +1,32 @@
+# Copyright 2025 Google LLC
+#
+# Licensed under the Apache License, Version 2.0 (the ""License"");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+from .base_agent import BaseAgent
+from .live_request_queue import LiveRequest
+from .live_request_queue import LiveRequestQueue
+from .llm_agent import Agent
+from .llm_agent import LlmAgent
+from .loop_agent import LoopAgent
+from .parallel_agent import ParallelAgent
+from .run_config import RunConfig
+from .sequential_agent import SequentialAgent
+
+__all__ = [
+    'Agent',
+    'BaseAgent',
+    'LlmAgent',
+    'LoopAgent',
+    'ParallelAgent',
+    'SequentialAgent',
+]
","diff --git a/src/google/adk/agents/__init__.py b/src/google/adk/agents/__init__.py
new file mode 100644
index 0000000..e1f773c
--- /dev/null
+++ b/src/google/adk/agents/__init__.py
@@ -0,0 +1,32 @@
+# Copyright 2025 Google LLC
+#
+# Licensed under the Apache License, Version 2.0 (the ""License"");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+from .base_agent import BaseAgent
+from .live_request_queue import LiveRequest
+from .live_request_queue import LiveRequestQueue
+from .llm_agent import Agent
+from .llm_agent import LlmAgent
+from .loop_agent import LoopAgent
+from .parallel_agent import ParallelAgent
+from .run_config import RunConfig
+from .sequential_agent import SequentialAgent
+
+__all__ = [
+    'Agent',
+    'BaseAgent',
+    'LlmAgent',
+    'LoopAgent',
+    'ParallelAgent',
+    'SequentialAgent',
+]
",No,SOURCE
adk-python,,pyproject.toml,98278201436cc7f642ede1b22407783e8c155b5e,f92478bd5c542c159e589e3603e70741c3677ab7,Agent Development Kit(ADK)  An easy-to-use and powerful framework to build AI agents.,"diff --git a/pyproject.toml b/pyproject.toml
new file mode 100644
index 0000000..05711d1
--- /dev/null
+++ b/pyproject.toml
@@ -0,0 +1,146 @@
+[project]
+# Project metadata. Available keys are documented at:
+# https://packaging.python.org/en/latest/specifications/declaring-project-metadata
+
+name = ""google-adk""
+description = ""Agent Development Kit""
+readme = ""README.md""
+requires-python = "">=3.9""
+license = { file = ""LICENSE"" }
+authors = [{ name = ""Google LLC"", email = ""googleapis-packages@google.com"" }]
+classifiers = [ # List of https://pypi.org/classifiers/
+  ""Typing :: Typed"",
+  ""Intended Audience :: Developers"",
+  ""Intended Audience :: Science/Research"",
+  ""Programming Language :: Python"",
+  ""Programming Language :: Python :: 3"",
+  ""Programming Language :: Python :: 3.9"",
+  ""Programming Language :: Python :: 3.13"",
+  ""Programming Language :: Python :: 3.12"",
+  ""Programming Language :: Python :: 3.11"",
+  ""Programming Language :: Python :: 3.10"",
+  ""Operating System :: OS Independent"",
+  ""Topic :: Software Development :: Libraries :: Python Modules"",
+  ""License :: OSI Approved :: Apache Software License"",
+]
+dependencies = [
+  # go/keep-sorted start
+  ""authlib>=1.5.1"",                          # For RestAPI Tool
+  ""click>=8.1.8"",                            # For CLI tools
+  ""fastapi>=0.115.0"",                        # FastAPI framework
+  ""google-api-python-client>=2.157.0"",       # Google API client discovery
+  ""google-cloud-aiplatform>=1.87.0"",         # For VertexAI integrations, e.g. example store.
+  ""google-cloud-secret-manager>=2.22.0"",     # Fetching secrets in RestAPI Tool
+  ""google-cloud-speech>=2.30.0"",             # For Audo Transcription
+  ""google-cloud-storage>=2.18.0, <3.0.0"",    # For GCS Artifact service
+  ""google-genai>=1.9.0"",                     # Google GenAI SDK
+  ""graphviz>=0.20.2"",                        # Graphviz for graph rendering
+  ""mcp>=1.5.0;python_version>='3.10'"",       # For MCP Toolset
+  ""opentelemetry-api>=1.31.0"",               # OpenTelemetry
+  ""opentelemetry-exporter-gcp-trace>=1.9.0"",
+  ""opentelemetry-sdk>=1.31.0"",
+  ""pydantic>=2.0, <3.0.0"",                   # For data validation/models
+  ""python-dotenv>=1.0.0"",                    # To manage environment variables
+  ""PyYAML>=6.0.2"",                           # For APIHubToolset.
+  ""sqlalchemy>=2.0"",                         # SQL database ORM
+  ""tzlocal>=5.3"",                            # Time zone utilities
+  ""uvicorn>=0.34.0"",                         # ASGI server for FastAPI
+  # go/keep-sorted end
+]
+dynamic = [""version""]
+
+[project.urls]
+homepage = ""https://google.github.io/adk-docs/""
+repository = ""https://github.com/google/adk-python""
+changelog = ""https://github.com/google/adk-python/blob/main/CHANGELOG.md""
+documentation = ""https://google.github.io/adk-docs/""
+
+[project.scripts]
+adk = ""google.adk.cli:main""
+
+[project.optional-dependencies]
+
+dev = [
+  # go/keep-sorted start
+  ""flit>=3.10.0"",
+  ""isort>=6.0.0"",
+  ""pyink>=24.10.0"",
+  ""pylint>=2.6.0"",
+  # go/keep-sorted end
+]
+
+eval = [
+  # go/keep-sorted start
+  ""google-cloud-aiplatform[evaluation]>=1.87.0"",
+  ""pandas>=2.2.3"",
+  ""tabulate>=0.9.0"",
+  # go/keep-sorted end
+]
+
+test = [
+  # go/keep-sorted start
+  ""langchain-community>=0.3.17"",
+  ""pytest-asyncio>=0.25.0"",
+  ""pytest-mock>=3.14.0"",
+  ""pytest-xdist>=3.6.1"",
+  ""pytest>=8.3.4"",
+  # go/keep-sorted end
+]
+
+docs = [
+  ""autodoc_pydantic"",
+  ""furo"",
+  ""myst-parser"",
+  ""sphinx"",
+  ""sphinx-autodoc-typehints"",
+  ""sphinx-rtd-theme"",
+]
+
+# Optional extensions
+extensions = [
+  ""anthropic>=0.43.0"",                    # For anthropic model support
+  ""beautifulsoup4>=3.2.2"",                # For load_web_page tool.
+  ""crewai[tools];python_version>='3.10'"", # For CrewaiTool
+  ""docker>=7.0.0"",                        # For ContainerCodeExecutor
+  ""langgraph>=0.2.60"",                    # For LangGraphAgent
+  ""litellm>=1.63.11"",                     # For LiteLLM support
+  ""llama-index-readers-file>=0.4.0"",      # for retrieval usings LlamaIndex.
+  ""lxml>=5.3.0"",                          # For load_web_page tool.
+]
+
+
+[tool.pyink]
+# Format py files following Google style-guide
+line-length = 80
+unstable = true
+pyink-indentation = 2
+pyink-use-majority-quotes = true
+
+
+[build-system]
+# Build system specify which backend is used to build/install the project (flit,
+# poetry, setuptools,...). All backends are supported by `pip install`
+requires = [""flit_core >=3.8,<4""]
+build-backend = ""flit_core.buildapi""
+
+[tool.flit.sdist]
+include = ['src/**/*', 'README.md', 'pyproject.toml']
+exclude = ['src/**/*.sh']
+
+[tool.flit.module]
+name = ""google.adk""
+
+[tool.isort]
+# Organize imports following Google style-guide
+force_single_line = true
+force_sort_within_sections = true
+honor_case_in_force_sorted_sections = true
+known_third_party = [""agents"", ""google""]
+order_by_type = false
+sort_relative_in_force_sorted_sections = true
+multi_line_output = 3
+line_length = 200
+
+[tool.pytest.ini_options]
+testpaths = [""tests""]
+asyncio_default_fixture_loop_scope = ""function""
","diff --git a/pyproject.toml b/pyproject.toml
new file mode 100644
index 0000000..05711d1
--- /dev/null
+++ b/pyproject.toml
@@ -0,0 +1,146 @@
+[project]
+# Project metadata. Available keys are documented at:
+# https://packaging.python.org/en/latest/specifications/declaring-project-metadata
+
+name = ""google-adk""
+description = ""Agent Development Kit""
+readme = ""README.md""
+requires-python = "">=3.9""
+license = { file = ""LICENSE"" }
+authors = [{ name = ""Google LLC"", email = ""googleapis-packages@google.com"" }]
+classifiers = [ # List of https://pypi.org/classifiers/
+  ""Typing :: Typed"",
+  ""Intended Audience :: Developers"",
+  ""Intended Audience :: Science/Research"",
+  ""Programming Language :: Python"",
+  ""Programming Language :: Python :: 3"",
+  ""Programming Language :: Python :: 3.9"",
+  ""Programming Language :: Python :: 3.13"",
+  ""Programming Language :: Python :: 3.12"",
+  ""Programming Language :: Python :: 3.11"",
+  ""Programming Language :: Python :: 3.10"",
+  ""Operating System :: OS Independent"",
+  ""Topic :: Software Development :: Libraries :: Python Modules"",
+  ""License :: OSI Approved :: Apache Software License"",
+]
+dependencies = [
+  # go/keep-sorted start
+  ""authlib>=1.5.1"",                          # For RestAPI Tool
+  ""click>=8.1.8"",                            # For CLI tools
+  ""fastapi>=0.115.0"",                        # FastAPI framework
+  ""google-api-python-client>=2.157.0"",       # Google API client discovery
+  ""google-cloud-aiplatform>=1.87.0"",         # For VertexAI integrations, e.g. example store.
+  ""google-cloud-secret-manager>=2.22.0"",     # Fetching secrets in RestAPI Tool
+  ""google-cloud-speech>=2.30.0"",             # For Audo Transcription
+  ""google-cloud-storage>=2.18.0, <3.0.0"",    # For GCS Artifact service
+  ""google-genai>=1.9.0"",                     # Google GenAI SDK
+  ""graphviz>=0.20.2"",                        # Graphviz for graph rendering
+  ""mcp>=1.5.0;python_version>='3.10'"",       # For MCP Toolset
+  ""opentelemetry-api>=1.31.0"",               # OpenTelemetry
+  ""opentelemetry-exporter-gcp-trace>=1.9.0"",
+  ""opentelemetry-sdk>=1.31.0"",
+  ""pydantic>=2.0, <3.0.0"",                   # For data validation/models
+  ""python-dotenv>=1.0.0"",                    # To manage environment variables
+  ""PyYAML>=6.0.2"",                           # For APIHubToolset.
+  ""sqlalchemy>=2.0"",                         # SQL database ORM
+  ""tzlocal>=5.3"",                            # Time zone utilities
+  ""uvicorn>=0.34.0"",                         # ASGI server for FastAPI
+  # go/keep-sorted end
+]
+dynamic = [""version""]
+
+[project.urls]
+homepage = ""https://google.github.io/adk-docs/""
+repository = ""https://github.com/google/adk-python""
+changelog = ""https://github.com/google/adk-python/blob/main/CHANGELOG.md""
+documentation = ""https://google.github.io/adk-docs/""
+
+[project.scripts]
+adk = ""google.adk.cli:main""
+
+[project.optional-dependencies]
+
+dev = [
+  # go/keep-sorted start
+  ""flit>=3.10.0"",
+  ""isort>=6.0.0"",
+  ""pyink>=24.10.0"",
+  ""pylint>=2.6.0"",
+  # go/keep-sorted end
+]
+
+eval = [
+  # go/keep-sorted start
+  ""google-cloud-aiplatform[evaluation]>=1.87.0"",
+  ""pandas>=2.2.3"",
+  ""tabulate>=0.9.0"",
+  # go/keep-sorted end
+]
+
+test = [
+  # go/keep-sorted start
+  ""langchain-community>=0.3.17"",
+  ""pytest-asyncio>=0.25.0"",
+  ""pytest-mock>=3.14.0"",
+  ""pytest-xdist>=3.6.1"",
+  ""pytest>=8.3.4"",
+  # go/keep-sorted end
+]
+
+docs = [
+  ""autodoc_pydantic"",
+  ""furo"",
+  ""myst-parser"",
+  ""sphinx"",
+  ""sphinx-autodoc-typehints"",
+  ""sphinx-rtd-theme"",
+]
+
+# Optional extensions
+extensions = [
+  ""anthropic>=0.43.0"",                    # For anthropic model support
+  ""beautifulsoup4>=3.2.2"",                # For load_web_page tool.
+  ""crewai[tools];python_version>='3.10'"", # For CrewaiTool
+  ""docker>=7.0.0"",                        # For ContainerCodeExecutor
+  ""langgraph>=0.2.60"",                    # For LangGraphAgent
+  ""litellm>=1.63.11"",                     # For LiteLLM support
+  ""llama-index-readers-file>=0.4.0"",      # for retrieval usings LlamaIndex.
+  ""lxml>=5.3.0"",                          # For load_web_page tool.
+]
+
+
+[tool.pyink]
+# Format py files following Google style-guide
+line-length = 80
+unstable = true
+pyink-indentation = 2
+pyink-use-majority-quotes = true
+
+
+[build-system]
+# Build system specify which backend is used to build/install the project (flit,
+# poetry, setuptools,...). All backends are supported by `pip install`
+requires = [""flit_core >=3.8,<4""]
+build-backend = ""flit_core.buildapi""
+
+[tool.flit.sdist]
+include = ['src/**/*', 'README.md', 'pyproject.toml']
+exclude = ['src/**/*.sh']
+
+[tool.flit.module]
+name = ""google.adk""
+
+[tool.isort]
+# Organize imports following Google style-guide
+force_single_line = true
+force_sort_within_sections = true
+honor_case_in_force_sorted_sections = true
+known_third_party = [""agents"", ""google""]
+order_by_type = false
+sort_relative_in_force_sorted_sections = true
+multi_line_output = 3
+line_length = 200
+
+[tool.pytest.ini_options]
+testpaths = [""tests""]
+asyncio_default_fixture_loop_scope = ""function""
",No,OTHER
adk-python,src/google/adk/sessions/database_session_service.py,src/google/adk/sessions/database_session_service.py,61d4be2d7675c3a8e0db098192b5c15dbc6234f2,290058eb05211ef531b1752c6290da3f365e4e73,No public description  PiperOrigin-RevId: 748777998,"diff --git a/src/google/adk/sessions/database_session_service.py b/src/google/adk/sessions/database_session_service.py
index 46f155d..53a14de 100644
--- a/src/google/adk/sessions/database_session_service.py
+++ b/src/google/adk/sessions/database_session_service.py
@@ -12,6 +12,7 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
+import base64
 import copy
 from datetime import datetime
 import json
@@ -20,17 +21,17 @@ from typing import Any
 from typing import Optional
 import uuid
 
+from sqlalchemy import Boolean
 from sqlalchemy import delete
 from sqlalchemy import Dialect
 from sqlalchemy import ForeignKeyConstraint
 from sqlalchemy import func
-from sqlalchemy import select
 from sqlalchemy import Text
 from sqlalchemy.dialects import postgresql
 from sqlalchemy.engine import create_engine
 from sqlalchemy.engine import Engine
-from sqlalchemy.ext.mutable import MutableDict
 from sqlalchemy.exc import ArgumentError
+from sqlalchemy.ext.mutable import MutableDict
 from sqlalchemy.inspection import inspect
 from sqlalchemy.orm import DeclarativeBase
 from sqlalchemy.orm import Mapped
@@ -54,6 +55,7 @@ from .base_session_service import ListSessionsResponse
 from .session import Session
 from .state import State
 
+
 logger = logging.getLogger(__name__)
 
 
@@ -103,7 +105,7 @@ class StorageSession(Base):
       String, primary_key=True, default=lambda: str(uuid.uuid4())
   )
 
-  state: Mapped[dict] = mapped_column(
+  state: Mapped[MutableDict[str, Any]] = mapped_column(
       MutableDict.as_mutable(DynamicJSON), default={}
   )
 
@@ -134,8 +136,20 @@ class StorageEvent(Base):
   author: Mapped[str] = mapped_column(String)
   branch: Mapped[str] = mapped_column(String, nullable=True)
   timestamp: Mapped[DateTime] = mapped_column(DateTime(), default=func.now())
-  content: Mapped[dict] = mapped_column(DynamicJSON)
-  actions: Mapped[dict] = mapped_column(PickleType)
+  content: Mapped[dict[str, Any]] = mapped_column(DynamicJSON)
+  actions: Mapped[MutableDict[str, Any]] = mapped_column(PickleType)
+
+  long_running_tool_ids_json: Mapped[Optional[str]] = mapped_column(
+      Text, nullable=True
+  )
+  grounding_metadata: Mapped[dict[str, Any]] = mapped_column(
+      DynamicJSON, nullable=True
+  )
+  partial: Mapped[bool] = mapped_column(Boolean, nullable=True)
+  turn_complete: Mapped[bool] = mapped_column(Boolean, nullable=True)
+  error_code: Mapped[str] = mapped_column(String, nullable=True)
+  error_message: Mapped[str] = mapped_column(String, nullable=True)
+  interrupted: Mapped[bool] = mapped_column(Boolean, nullable=True)
 
   storage_session: Mapped[StorageSession] = relationship(
       ""StorageSession"",
@@ -150,13 +164,28 @@ class StorageEvent(Base):
       ),
   )
 
+  @property
+  def long_running_tool_ids(self) -> set[str]:
+    return (
+        set(json.loads(self.long_running_tool_ids_json))
+        if self.long_running_tool_ids_json
+        else set()
+    )
+
+  @long_running_tool_ids.setter
+  def long_running_tool_ids(self, value: set[str]):
+    if value is None:
+      self.long_running_tool_ids_json = None
+    else:
+      self.long_running_tool_ids_json = json.dumps(list(value))
+
 
 class StorageAppState(Base):
   """"""Represents an app state stored in the database.""""""
   __tablename__ = ""app_states""
 
   app_name: Mapped[str] = mapped_column(String, primary_key=True)
-  state: Mapped[dict] = mapped_column(
+  state: Mapped[MutableDict[str, Any]] = mapped_column(
       MutableDict.as_mutable(DynamicJSON), default={}
   )
   update_time: Mapped[DateTime] = mapped_column(
@@ -170,7 +199,7 @@ class StorageUserState(Base):
 
   app_name: Mapped[str] = mapped_column(String, primary_key=True)
   user_id: Mapped[str] = mapped_column(String, primary_key=True)
-  state: Mapped[dict] = mapped_column(
+  state: Mapped[MutableDict[str, Any]] = mapped_column(
       MutableDict.as_mutable(DynamicJSON), default={}
   )
   update_time: Mapped[DateTime] = mapped_column(
@@ -295,7 +324,6 @@ class DatabaseSessionService(BaseSessionService):
           last_update_time=storage_session.update_time.timestamp(),
       )
       return session
-    return None
 
   @override
   def get_session(
@@ -309,7 +337,6 @@ class DatabaseSessionService(BaseSessionService):
     # 1. Get the storage session entry from session table
     # 2. Get all the events based on session id and filtering config
     # 3. Convert and return the session
-    session: Session = None
     with self.DatabaseSessionFactory() as sessionFactory:
       storage_session = sessionFactory.get(
           StorageSession, (app_name, user_id, session_id)
@@ -356,13 +383,19 @@ class DatabaseSessionService(BaseSessionService):
               author=e.author,
               branch=e.branch,
               invocation_id=e.invocation_id,
-              content=e.content,
+              content=_decode_content(e.content),
               actions=e.actions,
               timestamp=e.timestamp.timestamp(),
+              long_running_tool_ids=e.long_running_tool_ids,
+              grounding_metadata=e.grounding_metadata,
+              partial=e.partial,
+              turn_complete=e.turn_complete,
+              error_code=e.error_code,
+              error_message=e.error_message,
+              interrupted=e.interrupted,
           )
           for e in storage_events
       ]
-
     return session
 
   @override
@@ -387,7 +420,6 @@ class DatabaseSessionService(BaseSessionService):
         )
         sessions.append(session)
       return ListSessionsResponse(sessions=sessions)
-    raise ValueError(""Failed to retrieve sessions."")
 
   @override
   def delete_session(
@@ -406,7 +438,7 @@ class DatabaseSessionService(BaseSessionService):
   def append_event(self, session: Session, event: Event) -> Event:
     logger.info(f""Append event: {event} to session {session.id}"")
 
-    if event.partial and not event.content:
+    if event.partial:
       return event
 
     # 1. Check if timestamp is stale
@@ -455,19 +487,34 @@ class DatabaseSessionService(BaseSessionService):
       storage_user_state.state = user_state
       storage_session.state = session_state
 
-      encoded_content = event.content.model_dump(exclude_none=True)
       storage_event = StorageEvent(
           id=event.id,
           invocation_id=event.invocation_id,
           author=event.author,
           branch=event.branch,
-          content=encoded_content,
           actions=event.actions,
           session_id=session.id,
           app_name=session.app_name,
           user_id=session.user_id,
           timestamp=datetime.fromtimestamp(event.timestamp),
+          long_running_tool_ids=event.long_running_tool_ids,
+          grounding_metadata=event.grounding_metadata,
+          partial=event.partial,
+          turn_complete=event.turn_complete,
+          error_code=event.error_code,
+          error_message=event.error_message,
+          interrupted=event.interrupted,
+      )
+      if event.content:
+        encoded_content = event.content.model_dump(exclude_none=True)
+        # Workaround for multimodal Content throwing JSON not serializable
+        # error with SQLAlchemy.
+        for p in encoded_content[""parts""]:
+          if ""inline_data"" in p:
+            p[""inline_data""][""data""] = (
+                base64.b64encode(p[""inline_data""][""data""]).decode(""utf-8""),
             )
+        storage_event.content = encoded_content
 
       sessionFactory.add(storage_event)
 
@@ -489,8 +536,7 @@ class DatabaseSessionService(BaseSessionService):
       user_id: str,
       session_id: str,
   ) -> ListEventsResponse:
-    pass
-
+    raise NotImplementedError()
 
 def convert_event(event: StorageEvent) -> Event:
   """"""Converts a storage event to an event.""""""
@@ -505,7 +551,7 @@ def convert_event(event: StorageEvent) -> Event:
   )
 
 
-def _extract_state_delta(state: dict):
+def _extract_state_delta(state: dict[str, Any]):
   app_state_delta = {}
   user_state_delta = {}
   session_state_delta = {}
@@ -528,3 +574,10 @@ def _merge_state(app_state, user_state, session_state):
   for key in user_state.keys():
     merged_state[State.USER_PREFIX + key] = user_state[key]
   return merged_state
+
+
+def _decode_content(content: dict[str, Any]) -> dict[str, Any]:
+  for p in content[""parts""]:
+    if ""inline_data"" in p:
+      p[""inline_data""][""data""] = base64.b64decode(p[""inline_data""][""data""][0])
+  return content
","diff --git a/src/google/adk/sessions/database_session_service.py b/src/google/adk/sessions/database_session_service.py
index 46f155d..53a14de 100644
--- a/src/google/adk/sessions/database_session_service.py
+++ b/src/google/adk/sessions/database_session_service.py
@@ -12,6 +12,7 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
+import base64
 import copy
 from datetime import datetime
 import json
@@ -20,17 +21,17 @@ from typing import Any
 from typing import Optional
 import uuid
 
+from sqlalchemy import Boolean
 from sqlalchemy import delete
 from sqlalchemy import Dialect
 from sqlalchemy import ForeignKeyConstraint
 from sqlalchemy import func
-from sqlalchemy import select
 from sqlalchemy import Text
 from sqlalchemy.dialects import postgresql
 from sqlalchemy.engine import create_engine
 from sqlalchemy.engine import Engine
-from sqlalchemy.ext.mutable import MutableDict
 from sqlalchemy.exc import ArgumentError
+from sqlalchemy.ext.mutable import MutableDict
 from sqlalchemy.inspection import inspect
 from sqlalchemy.orm import DeclarativeBase
 from sqlalchemy.orm import Mapped
@@ -54,6 +55,7 @@ from .base_session_service import ListSessionsResponse
 from .session import Session
 from .state import State
 
+
 logger = logging.getLogger(__name__)
 
 
@@ -103,7 +105,7 @@ class StorageSession(Base):
       String, primary_key=True, default=lambda: str(uuid.uuid4())
   )
 
-  state: Mapped[dict] = mapped_column(
+  state: Mapped[MutableDict[str, Any]] = mapped_column(
       MutableDict.as_mutable(DynamicJSON), default={}
   )
 
@@ -134,8 +136,20 @@ class StorageEvent(Base):
   author: Mapped[str] = mapped_column(String)
   branch: Mapped[str] = mapped_column(String, nullable=True)
   timestamp: Mapped[DateTime] = mapped_column(DateTime(), default=func.now())
-  content: Mapped[dict] = mapped_column(DynamicJSON)
-  actions: Mapped[dict] = mapped_column(PickleType)
+  content: Mapped[dict[str, Any]] = mapped_column(DynamicJSON)
+  actions: Mapped[MutableDict[str, Any]] = mapped_column(PickleType)
+
+  long_running_tool_ids_json: Mapped[Optional[str]] = mapped_column(
+      Text, nullable=True
+  )
+  grounding_metadata: Mapped[dict[str, Any]] = mapped_column(
+      DynamicJSON, nullable=True
+  )
+  partial: Mapped[bool] = mapped_column(Boolean, nullable=True)
+  turn_complete: Mapped[bool] = mapped_column(Boolean, nullable=True)
+  error_code: Mapped[str] = mapped_column(String, nullable=True)
+  error_message: Mapped[str] = mapped_column(String, nullable=True)
+  interrupted: Mapped[bool] = mapped_column(Boolean, nullable=True)
 
   storage_session: Mapped[StorageSession] = relationship(
       ""StorageSession"",
@@ -150,13 +164,28 @@ class StorageEvent(Base):
       ),
   )
 
+  @property
+  def long_running_tool_ids(self) -> set[str]:
+    return (
+        set(json.loads(self.long_running_tool_ids_json))
+        if self.long_running_tool_ids_json
+        else set()
+    )
+
+  @long_running_tool_ids.setter
+  def long_running_tool_ids(self, value: set[str]):
+    if value is None:
+      self.long_running_tool_ids_json = None
+    else:
+      self.long_running_tool_ids_json = json.dumps(list(value))
+
 
 class StorageAppState(Base):
   """"""Represents an app state stored in the database.""""""
   __tablename__ = ""app_states""
 
   app_name: Mapped[str] = mapped_column(String, primary_key=True)
-  state: Mapped[dict] = mapped_column(
+  state: Mapped[MutableDict[str, Any]] = mapped_column(
       MutableDict.as_mutable(DynamicJSON), default={}
   )
   update_time: Mapped[DateTime] = mapped_column(
@@ -170,7 +199,7 @@ class StorageUserState(Base):
 
   app_name: Mapped[str] = mapped_column(String, primary_key=True)
   user_id: Mapped[str] = mapped_column(String, primary_key=True)
-  state: Mapped[dict] = mapped_column(
+  state: Mapped[MutableDict[str, Any]] = mapped_column(
       MutableDict.as_mutable(DynamicJSON), default={}
   )
   update_time: Mapped[DateTime] = mapped_column(
@@ -295,7 +324,6 @@ class DatabaseSessionService(BaseSessionService):
           last_update_time=storage_session.update_time.timestamp(),
       )
       return session
-    return None
 
   @override
   def get_session(
@@ -309,7 +337,6 @@ class DatabaseSessionService(BaseSessionService):
     # 1. Get the storage session entry from session table
     # 2. Get all the events based on session id and filtering config
     # 3. Convert and return the session
-    session: Session = None
     with self.DatabaseSessionFactory() as sessionFactory:
       storage_session = sessionFactory.get(
           StorageSession, (app_name, user_id, session_id)
@@ -356,13 +383,19 @@ class DatabaseSessionService(BaseSessionService):
               author=e.author,
               branch=e.branch,
               invocation_id=e.invocation_id,
-              content=e.content,
+              content=_decode_content(e.content),
               actions=e.actions,
               timestamp=e.timestamp.timestamp(),
+              long_running_tool_ids=e.long_running_tool_ids,
+              grounding_metadata=e.grounding_metadata,
+              partial=e.partial,
+              turn_complete=e.turn_complete,
+              error_code=e.error_code,
+              error_message=e.error_message,
+              interrupted=e.interrupted,
           )
           for e in storage_events
       ]
-
     return session
 
   @override
@@ -387,7 +420,6 @@ class DatabaseSessionService(BaseSessionService):
         )
         sessions.append(session)
       return ListSessionsResponse(sessions=sessions)
-    raise ValueError(""Failed to retrieve sessions."")
 
   @override
   def delete_session(
@@ -406,7 +438,7 @@ class DatabaseSessionService(BaseSessionService):
   def append_event(self, session: Session, event: Event) -> Event:
     logger.info(f""Append event: {event} to session {session.id}"")
 
-    if event.partial and not event.content:
+    if event.partial:
       return event
 
     # 1. Check if timestamp is stale
@@ -455,19 +487,34 @@ class DatabaseSessionService(BaseSessionService):
       storage_user_state.state = user_state
       storage_session.state = session_state
 
-      encoded_content = event.content.model_dump(exclude_none=True)
       storage_event = StorageEvent(
           id=event.id,
           invocation_id=event.invocation_id,
           author=event.author,
           branch=event.branch,
-          content=encoded_content,
           actions=event.actions,
           session_id=session.id,
           app_name=session.app_name,
           user_id=session.user_id,
           timestamp=datetime.fromtimestamp(event.timestamp),
+          long_running_tool_ids=event.long_running_tool_ids,
+          grounding_metadata=event.grounding_metadata,
+          partial=event.partial,
+          turn_complete=event.turn_complete,
+          error_code=event.error_code,
+          error_message=event.error_message,
+          interrupted=event.interrupted,
       )
+      if event.content:
+        encoded_content = event.content.model_dump(exclude_none=True)
+        # Workaround for multimodal Content throwing JSON not serializable
+        # error with SQLAlchemy.
+        for p in encoded_content[""parts""]:
+          if ""inline_data"" in p:
+            p[""inline_data""][""data""] = (
+                base64.b64encode(p[""inline_data""][""data""]).decode(""utf-8""),
+            )
+        storage_event.content = encoded_content
 
       sessionFactory.add(storage_event)
 
@@ -489,8 +536,7 @@ class DatabaseSessionService(BaseSessionService):
       user_id: str,
       session_id: str,
   ) -> ListEventsResponse:
-    pass
-
+    raise NotImplementedError()
 
 def convert_event(event: StorageEvent) -> Event:
   """"""Converts a storage event to an event.""""""
@@ -505,7 +551,7 @@ def convert_event(event: StorageEvent) -> Event:
   )
 
 
-def _extract_state_delta(state: dict):
+def _extract_state_delta(state: dict[str, Any]):
   app_state_delta = {}
   user_state_delta = {}
   session_state_delta = {}
@@ -528,3 +574,10 @@ def _merge_state(app_state, user_state, session_state):
   for key in user_state.keys():
     merged_state[State.USER_PREFIX + key] = user_state[key]
   return merged_state
+
+
+def _decode_content(content: dict[str, Any]) -> dict[str, Any]:
+  for p in content[""parts""]:
+    if ""inline_data"" in p:
+      p[""inline_data""][""data""] = base64.b64decode(p[""inline_data""][""data""][0])
+  return content
",Yes,SOURCE
adk-python,src/google/adk/memory/base_memory_service.py,src/google/adk/memory/base_memory_service.py,30947b48b869343e1f9fee1824888b0d15546874,825f5d4f2e4a10db9c87d278caeb37db4b9b7a8f,feat(memory)!: Uses the new MemoryEntry schema for all memory related components.  BREAKING CHANGE. This commit changes all memory related interface to using the newly introduced MemoryEntry class.  PiperOrigin-RevId: 758464887,"diff --git a/src/google/adk/memory/base_memory_service.py b/src/google/adk/memory/base_memory_service.py
index 86ceba9..65932de 100644
--- a/src/google/adk/memory/base_memory_service.py
+++ b/src/google/adk/memory/base_memory_service.py
@@ -12,46 +12,44 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-import abc
 
-from pydantic import BaseModel
-from pydantic import Field
+from __future__ import annotations
 
-from ..events.event import Event
-from ..sessions.session import Session
+from abc import ABC
+from abc import abstractmethod
+from typing import TYPE_CHECKING
 
+from pydantic import BaseModel
+from pydantic import Field
 
-class MemoryResult(BaseModel):
-  """"""Represents a single memory retrieval result.
-
-  Attributes:
-      session_id: The session id associated with the memory.
-      events: A list of events in the session.
-  """"""
+from .memory_entry import MemoryEntry
 
-  session_id: str
-  events: list[Event]
+if TYPE_CHECKING:
+  from ..sessions.session import Session
 
 
 class SearchMemoryResponse(BaseModel):
   """"""Represents the response from a memory search.
 
   Attributes:
-      memories: A list of memory results matching the search query.
+      memories: A list of memory entries that relate to the search query.
   """"""
 
-  memories: list[MemoryResult] = Field(default_factory=list)
+  memories: list[MemoryEntry] = Field(default_factory=list)
 
 
-class BaseMemoryService(abc.ABC):
+class BaseMemoryService(ABC):
   """"""Base class for memory services.
 
   The service provides functionalities to ingest sessions into memory so that
   the memory can be used for user queries.
   """"""
 
-  @abc.abstractmethod
-  async def add_session_to_memory(self, session: Session):
+  @abstractmethod
+  async def add_session_to_memory(
+      self,
+      session: Session,
+  ):
     """"""Adds a session to the memory service.
 
     A session may be added multiple times during its lifetime.
@@ -60,9 +58,13 @@ class BaseMemoryService(abc.ABC):
         session: The session to add.
     """"""
 
-  @abc.abstractmethod
+  @abstractmethod
   async def search_memory(
-      self, *, app_name: str, user_id: str, query: str
+      self,
+      *,
+      app_name: str,
+      user_id: str,
+      query: str,
   ) -> SearchMemoryResponse:
     """"""Searches for sessions that match the query.
 
","diff --git a/src/google/adk/memory/base_memory_service.py b/src/google/adk/memory/base_memory_service.py
index 86ceba9..65932de 100644
--- a/src/google/adk/memory/base_memory_service.py
+++ b/src/google/adk/memory/base_memory_service.py
@@ -12,46 +12,44 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-import abc
+
+from __future__ import annotations
+
+from abc import ABC
+from abc import abstractmethod
+from typing import TYPE_CHECKING
 
 from pydantic import BaseModel
 from pydantic import Field
 
-from ..events.event import Event
+from .memory_entry import MemoryEntry
+
+if TYPE_CHECKING:
   from ..sessions.session import Session
 
 
-class MemoryResult(BaseModel):
-  """"""Represents a single memory retrieval result.
-
-  Attributes:
-      session_id: The session id associated with the memory.
-      events: A list of events in the session.
-  """"""
-
-  session_id: str
-  events: list[Event]
-
-
 class SearchMemoryResponse(BaseModel):
   """"""Represents the response from a memory search.
 
   Attributes:
-      memories: A list of memory results matching the search query.
+      memories: A list of memory entries that relate to the search query.
   """"""
 
-  memories: list[MemoryResult] = Field(default_factory=list)
+  memories: list[MemoryEntry] = Field(default_factory=list)
 
 
-class BaseMemoryService(abc.ABC):
+class BaseMemoryService(ABC):
   """"""Base class for memory services.
 
   The service provides functionalities to ingest sessions into memory so that
   the memory can be used for user queries.
   """"""
 
-  @abc.abstractmethod
-  async def add_session_to_memory(self, session: Session):
+  @abstractmethod
+  async def add_session_to_memory(
+      self,
+      session: Session,
+  ):
     """"""Adds a session to the memory service.
 
     A session may be added multiple times during its lifetime.
@@ -60,9 +58,13 @@ class BaseMemoryService(abc.ABC):
         session: The session to add.
     """"""
 
-  @abc.abstractmethod
+  @abstractmethod
   async def search_memory(
-      self, *, app_name: str, user_id: str, query: str
+      self,
+      *,
+      app_name: str,
+      user_id: str,
+      query: str,
   ) -> SearchMemoryResponse:
     """"""Searches for sessions that match the query.
 
",Yes,SOURCE
adk-python,src/google/adk/tools/apihub_tool/apihub_toolset.py,src/google/adk/tools/apihub_tool/apihub_toolset.py,6a04ff84bac7c8f79e94b84daabfb6f39154b00c,27b229719e6622de89dcaf65053734f249e23c06,adapt google api toolset and api hub toolset to new toolset interface  PiperOrigin-RevId: 757946541,"diff --git a/src/google/adk/tools/apihub_tool/apihub_toolset.py b/src/google/adk/tools/apihub_tool/apihub_toolset.py
index 0cf160e..8acf1b7 100644
--- a/src/google/adk/tools/apihub_tool/apihub_toolset.py
+++ b/src/google/adk/tools/apihub_tool/apihub_toolset.py
@@ -13,19 +13,25 @@
 # limitations under the License.
 
 
-from typing import Dict, List, Optional
+from typing import List
+from typing import Optional
+from typing import override
+from typing import Union
 
 import yaml
 
+from ...agents.readonly_context import ReadonlyContext
 from ...auth.auth_credential import AuthCredential
 from ...auth.auth_schemes import AuthScheme
+from ..base_toolset import BaseToolset
+from ..base_toolset import ToolPredicate
 from ..openapi_tool.common.common import to_snake_case
 from ..openapi_tool.openapi_spec_parser.openapi_toolset import OpenAPIToolset
 from ..openapi_tool.openapi_spec_parser.rest_api_tool import RestApiTool
 from .clients.apihub_client import APIHubClient
 
 
-class APIHubToolset:
+class APIHubToolset(BaseToolset):
   """"""APIHubTool generates tools from a given API Hub resource.
 
   Examples:
@@ -34,16 +40,13 @@ class APIHubToolset:
   apihub_toolset = APIHubToolset(
       apihub_resource_name=""projects/test-project/locations/us-central1/apis/test-api"",
       service_account_json=""..."",
+      tool_filter=lambda tool, ctx=None: tool.name in ('my_tool',
+      'my_other_tool')
   )
 
   # Get all available tools
-  agent = LlmAgent(tools=apihub_toolset.get_tools())
+  agent = LlmAgent(tools=apihub_toolset)
 
-  # Get a specific tool
-  agent = LlmAgent(tools=[
-      ...
-      apihub_toolset.get_tool('my_tool'),
-  ])
   ```
 
   **apihub_resource_name** is the resource name from API Hub. It must include
@@ -70,6 +73,7 @@ class APIHubToolset:
       auth_credential: Optional[AuthCredential] = None,
       # Optionally, you can provide a custom API Hub client
       apihub_client: Optional[APIHubClient] = None,
+      tool_filter: Optional[Union[ToolPredicate, List[str]]] = None,
   ):
     """"""Initializes the APIHubTool with the given parameters.
 
@@ -81,12 +85,17 @@ class APIHubToolset:
     )
 
     # Get all available tools
-    agent = LlmAgent(tools=apihub_toolset.get_tools())
+    agent = LlmAgent(tools=[apihub_toolset])
 
+    apihub_toolset = APIHubToolset(
+        apihub_resource_name=""projects/test-project/locations/us-central1/apis/test-api"",
+        service_account_json=""..."",
+        tool_filter = ['my_tool']
+    )
     # Get a specific tool
     agent = LlmAgent(tools=[
-        ...
-        apihub_toolset.get_tool('my_tool'),
+        ...,
+        apihub_toolset,
     ])
     ```
 
@@ -118,6 +127,9 @@ class APIHubToolset:
         lazy_load_spec: If True, the spec will be loaded lazily when needed.
           Otherwise, the spec will be loaded immediately and the tools will be
           generated during initialization.
+        tool_filter: The filter used to filter the tools in the toolset. It can
+          be either a tool predicate or a list of tool names of the tools to
+          expose.
     """"""
     self.name = name
     self.description = description
@@ -128,72 +140,36 @@ class APIHubToolset:
         service_account_json=service_account_json,
     )
 
-    self.generated_tools: Dict[str, RestApiTool] = {}
+    self.openapi_toolset = None
     self.auth_scheme = auth_scheme
     self.auth_credential = auth_credential
+    self.tool_filter = tool_filter
 
     if not self.lazy_load_spec:
-      self._prepare_tools()
-
-  def get_tool(self, name: str) -> Optional[RestApiTool]:
-    """"""Retrieves a specific tool by its name.
-
-    Example:
-    ```
-    apihub_tool = apihub_toolset.get_tool('my_tool')
-    ```
-
-    Args:
-        name: The name of the tool to retrieve.
-
-    Returns:
-        The tool with the given name, or None if no such tool exists.
-    """"""
-    if not self._are_tools_ready():
-      self._prepare_tools()
+      self._prepare_toolset()
 
-    return self.generated_tools[name] if name in self.generated_tools else None
-
-  def get_tools(self) -> List[RestApiTool]:
+  @override
+  async def get_tools(
+      self, readonly_context: Optional[ReadonlyContext] = None
+  ) -> List[RestApiTool]:
     """"""Retrieves all available tools.
 
     Returns:
         A list of all available RestApiTool objects.
     """"""
-    if not self._are_tools_ready():
-      self._prepare_tools()
-
-    return list(self.generated_tools.values())
-
-  def _are_tools_ready(self) -> bool:
-    return not self.lazy_load_spec or self.generated_tools
-
-  def _prepare_tools(self) -> str:
-    """"""Fetches the spec from API Hub and generates the tools.
+    if not self.openapi_toolset:
+      self._prepare_toolset()
+    if not self.openapi_toolset:
+      return []
+    return await self.openapi_toolset.get_tools(readonly_context)
 
-    Returns:
-        True if the tools are ready, False otherwise.
-    """"""
+  def _prepare_toolset(self) -> None:
+    """"""Fetches the spec from API Hub and generates the toolset.""""""
     # For each API, get the first version and the first spec of that version.
-    spec = self.apihub_client.get_spec_content(self.apihub_resource_name)
-    self.generated_tools: Dict[str, RestApiTool] = {}
-
-    tools = self._parse_spec_to_tools(spec)
-    for tool in tools:
-      self.generated_tools[tool.name] = tool
-
-  def _parse_spec_to_tools(self, spec_str: str) -> List[RestApiTool]:
-    """"""Parses the spec string to a list of RestApiTool.
-
-    Args:
-        spec_str: The spec string to parse.
-
-    Returns:
-        A list of RestApiTool objects.
-    """"""
+    spec_str = self.apihub_client.get_spec_content(self.apihub_resource_name)
     spec_dict = yaml.safe_load(spec_str)
     if not spec_dict:
-      return []
+      return
 
     self.name = self.name or to_snake_case(
         spec_dict.get('info', {}).get('title', 'unnamed')
@@ -201,9 +177,14 @@ class APIHubToolset:
     self.description = self.description or spec_dict.get('info', {}).get(
         'description', ''
     )
-    tools = OpenAPIToolset(
+    self.openapi_toolset = OpenAPIToolset(
         spec_dict=spec_dict,
         auth_credential=self.auth_credential,
         auth_scheme=self.auth_scheme,
-    ).get_tools()
-    return tools
+        tool_filter=self.tool_filter,
+    )
+
+  @override
+  async def close(self):
+    if self.openapi_toolset:
+      await self.openapi_toolset.close()
","diff --git a/src/google/adk/tools/apihub_tool/apihub_toolset.py b/src/google/adk/tools/apihub_tool/apihub_toolset.py
index 0cf160e..8acf1b7 100644
--- a/src/google/adk/tools/apihub_tool/apihub_toolset.py
+++ b/src/google/adk/tools/apihub_tool/apihub_toolset.py
@@ -13,19 +13,25 @@
 # limitations under the License.
 
 
-from typing import Dict, List, Optional
+from typing import List
+from typing import Optional
+from typing import override
+from typing import Union
 
 import yaml
 
+from ...agents.readonly_context import ReadonlyContext
 from ...auth.auth_credential import AuthCredential
 from ...auth.auth_schemes import AuthScheme
+from ..base_toolset import BaseToolset
+from ..base_toolset import ToolPredicate
 from ..openapi_tool.common.common import to_snake_case
 from ..openapi_tool.openapi_spec_parser.openapi_toolset import OpenAPIToolset
 from ..openapi_tool.openapi_spec_parser.rest_api_tool import RestApiTool
 from .clients.apihub_client import APIHubClient
 
 
-class APIHubToolset:
+class APIHubToolset(BaseToolset):
   """"""APIHubTool generates tools from a given API Hub resource.
 
   Examples:
@@ -34,16 +40,13 @@ class APIHubToolset:
   apihub_toolset = APIHubToolset(
       apihub_resource_name=""projects/test-project/locations/us-central1/apis/test-api"",
       service_account_json=""..."",
+      tool_filter=lambda tool, ctx=None: tool.name in ('my_tool',
+      'my_other_tool')
   )
 
   # Get all available tools
-  agent = LlmAgent(tools=apihub_toolset.get_tools())
+  agent = LlmAgent(tools=apihub_toolset)
 
-  # Get a specific tool
-  agent = LlmAgent(tools=[
-      ...
-      apihub_toolset.get_tool('my_tool'),
-  ])
   ```
 
   **apihub_resource_name** is the resource name from API Hub. It must include
@@ -70,6 +73,7 @@ class APIHubToolset:
       auth_credential: Optional[AuthCredential] = None,
       # Optionally, you can provide a custom API Hub client
       apihub_client: Optional[APIHubClient] = None,
+      tool_filter: Optional[Union[ToolPredicate, List[str]]] = None,
   ):
     """"""Initializes the APIHubTool with the given parameters.
 
@@ -81,12 +85,17 @@ class APIHubToolset:
     )
 
     # Get all available tools
-    agent = LlmAgent(tools=apihub_toolset.get_tools())
+    agent = LlmAgent(tools=[apihub_toolset])
 
+    apihub_toolset = APIHubToolset(
+        apihub_resource_name=""projects/test-project/locations/us-central1/apis/test-api"",
+        service_account_json=""..."",
+        tool_filter = ['my_tool']
+    )
     # Get a specific tool
     agent = LlmAgent(tools=[
-        ...
-        apihub_toolset.get_tool('my_tool'),
+        ...,
+        apihub_toolset,
     ])
     ```
 
@@ -118,6 +127,9 @@ class APIHubToolset:
         lazy_load_spec: If True, the spec will be loaded lazily when needed.
           Otherwise, the spec will be loaded immediately and the tools will be
           generated during initialization.
+        tool_filter: The filter used to filter the tools in the toolset. It can
+          be either a tool predicate or a list of tool names of the tools to
+          expose.
     """"""
     self.name = name
     self.description = description
@@ -128,72 +140,36 @@ class APIHubToolset:
         service_account_json=service_account_json,
     )
 
-    self.generated_tools: Dict[str, RestApiTool] = {}
+    self.openapi_toolset = None
     self.auth_scheme = auth_scheme
     self.auth_credential = auth_credential
+    self.tool_filter = tool_filter
 
     if not self.lazy_load_spec:
-      self._prepare_tools()
+      self._prepare_toolset()
 
-  def get_tool(self, name: str) -> Optional[RestApiTool]:
-    """"""Retrieves a specific tool by its name.
-
-    Example:
-    ```
-    apihub_tool = apihub_toolset.get_tool('my_tool')
-    ```
-
-    Args:
-        name: The name of the tool to retrieve.
-
-    Returns:
-        The tool with the given name, or None if no such tool exists.
-    """"""
-    if not self._are_tools_ready():
-      self._prepare_tools()
-
-    return self.generated_tools[name] if name in self.generated_tools else None
-
-  def get_tools(self) -> List[RestApiTool]:
+  @override
+  async def get_tools(
+      self, readonly_context: Optional[ReadonlyContext] = None
+  ) -> List[RestApiTool]:
     """"""Retrieves all available tools.
 
     Returns:
         A list of all available RestApiTool objects.
     """"""
-    if not self._are_tools_ready():
-      self._prepare_tools()
+    if not self.openapi_toolset:
+      self._prepare_toolset()
+    if not self.openapi_toolset:
+      return []
+    return await self.openapi_toolset.get_tools(readonly_context)
 
-    return list(self.generated_tools.values())
-
-  def _are_tools_ready(self) -> bool:
-    return not self.lazy_load_spec or self.generated_tools
-
-  def _prepare_tools(self) -> str:
-    """"""Fetches the spec from API Hub and generates the tools.
-
-    Returns:
-        True if the tools are ready, False otherwise.
-    """"""
+  def _prepare_toolset(self) -> None:
+    """"""Fetches the spec from API Hub and generates the toolset.""""""
     # For each API, get the first version and the first spec of that version.
-    spec = self.apihub_client.get_spec_content(self.apihub_resource_name)
-    self.generated_tools: Dict[str, RestApiTool] = {}
-
-    tools = self._parse_spec_to_tools(spec)
-    for tool in tools:
-      self.generated_tools[tool.name] = tool
-
-  def _parse_spec_to_tools(self, spec_str: str) -> List[RestApiTool]:
-    """"""Parses the spec string to a list of RestApiTool.
-
-    Args:
-        spec_str: The spec string to parse.
-
-    Returns:
-        A list of RestApiTool objects.
-    """"""
+    spec_str = self.apihub_client.get_spec_content(self.apihub_resource_name)
     spec_dict = yaml.safe_load(spec_str)
     if not spec_dict:
-      return []
+      return
 
     self.name = self.name or to_snake_case(
         spec_dict.get('info', {}).get('title', 'unnamed')
@@ -201,9 +177,14 @@ class APIHubToolset:
     self.description = self.description or spec_dict.get('info', {}).get(
         'description', ''
     )
-    tools = OpenAPIToolset(
+    self.openapi_toolset = OpenAPIToolset(
         spec_dict=spec_dict,
         auth_credential=self.auth_credential,
         auth_scheme=self.auth_scheme,
-    ).get_tools()
-    return tools
+        tool_filter=self.tool_filter,
+    )
+
+  @override
+  async def close(self):
+    if self.openapi_toolset:
+      await self.openapi_toolset.close()
",Yes,SOURCE
adk-python,,LICENSE,98278201436cc7f642ede1b22407783e8c155b5e,f92478bd5c542c159e589e3603e70741c3677ab7,Agent Development Kit(ADK)  An easy-to-use and powerful framework to build AI agents.,"diff --git a/LICENSE b/LICENSE
new file mode 100644
index 0000000..7a4a3ea
--- /dev/null
+++ b/LICENSE
@@ -0,0 +1,202 @@
+
+                                 Apache License
+                           Version 2.0, January 2004
+                        http://www.apache.org/licenses/
+
+   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
+
+   1. Definitions.
+
+      ""License"" shall mean the terms and conditions for use, reproduction,
+      and distribution as defined by Sections 1 through 9 of this document.
+
+      ""Licensor"" shall mean the copyright owner or entity authorized by
+      the copyright owner that is granting the License.
+
+      ""Legal Entity"" shall mean the union of the acting entity and all
+      other entities that control, are controlled by, or are under common
+      control with that entity. For the purposes of this definition,
+      ""control"" means (i) the power, direct or indirect, to cause the
+      direction or management of such entity, whether by contract or
+      otherwise, or (ii) ownership of fifty percent (50%) or more of the
+      outstanding shares, or (iii) beneficial ownership of such entity.
+
+      ""You"" (or ""Your"") shall mean an individual or Legal Entity
+      exercising permissions granted by this License.
+
+      ""Source"" form shall mean the preferred form for making modifications,
+      including but not limited to software source code, documentation
+      source, and configuration files.
+
+      ""Object"" form shall mean any form resulting from mechanical
+      transformation or translation of a Source form, including but
+      not limited to compiled object code, generated documentation,
+      and conversions to other media types.
+
+      ""Work"" shall mean the work of authorship, whether in Source or
+      Object form, made available under the License, as indicated by a
+      copyright notice that is included in or attached to the work
+      (an example is provided in the Appendix below).
+
+      ""Derivative Works"" shall mean any work, whether in Source or Object
+      form, that is based on (or derived from) the Work and for which the
+      editorial revisions, annotations, elaborations, or other modifications
+      represent, as a whole, an original work of authorship. For the purposes
+      of this License, Derivative Works shall not include works that remain
+      separable from, or merely link (or bind by name) to the interfaces of,
+      the Work and Derivative Works thereof.
+
+      ""Contribution"" shall mean any work of authorship, including
+      the original version of the Work and any modifications or additions
+      to that Work or Derivative Works thereof, that is intentionally
+      submitted to Licensor for inclusion in the Work by the copyright owner
+      or by an individual or Legal Entity authorized to submit on behalf of
+      the copyright owner. For the purposes of this definition, ""submitted""
+      means any form of electronic, verbal, or written communication sent
+      to the Licensor or its representatives, including but not limited to
+      communication on electronic mailing lists, source code control systems,
+      and issue tracking systems that are managed by, or on behalf of, the
+      Licensor for the purpose of discussing and improving the Work, but
+      excluding communication that is conspicuously marked or otherwise
+      designated in writing by the copyright owner as ""Not a Contribution.""
+
+      ""Contributor"" shall mean Licensor and any individual or Legal Entity
+      on behalf of whom a Contribution has been received by Licensor and
+      subsequently incorporated within the Work.
+
+   2. Grant of Copyright License. Subject to the terms and conditions of
+      this License, each Contributor hereby grants to You a perpetual,
+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+      copyright license to reproduce, prepare Derivative Works of,
+      publicly display, publicly perform, sublicense, and distribute the
+      Work and such Derivative Works in Source or Object form.
+
+   3. Grant of Patent License. Subject to the terms and conditions of
+      this License, each Contributor hereby grants to You a perpetual,
+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+      (except as stated in this section) patent license to make, have made,
+      use, offer to sell, sell, import, and otherwise transfer the Work,
+      where such license applies only to those patent claims licensable
+      by such Contributor that are necessarily infringed by their
+      Contribution(s) alone or by combination of their Contribution(s)
+      with the Work to which such Contribution(s) was submitted. If You
+      institute patent litigation against any entity (including a
+      cross-claim or counterclaim in a lawsuit) alleging that the Work
+      or a Contribution incorporated within the Work constitutes direct
+      or contributory patent infringement, then any patent licenses
+      granted to You under this License for that Work shall terminate
+      as of the date such litigation is filed.
+
+   4. Redistribution. You may reproduce and distribute copies of the
+      Work or Derivative Works thereof in any medium, with or without
+      modifications, and in Source or Object form, provided that You
+      meet the following conditions:
+
+      (a) You must give any other recipients of the Work or
+          Derivative Works a copy of this License; and
+
+      (b) You must cause any modified files to carry prominent notices
+          stating that You changed the files; and
+
+      (c) You must retain, in the Source form of any Derivative Works
+          that You distribute, all copyright, patent, trademark, and
+          attribution notices from the Source form of the Work,
+          excluding those notices that do not pertain to any part of
+          the Derivative Works; and
+
+      (d) If the Work includes a ""NOTICE"" text file as part of its
+          distribution, then any Derivative Works that You distribute must
+          include a readable copy of the attribution notices contained
+          within such NOTICE file, excluding those notices that do not
+          pertain to any part of the Derivative Works, in at least one
+          of the following places: within a NOTICE text file distributed
+          as part of the Derivative Works; within the Source form or
+          documentation, if provided along with the Derivative Works; or,
+          within a display generated by the Derivative Works, if and
+          wherever such third-party notices normally appear. The contents
+          of the NOTICE file are for informational purposes only and
+          do not modify the License. You may add Your own attribution
+          notices within Derivative Works that You distribute, alongside
+          or as an addendum to the NOTICE text from the Work, provided
+          that such additional attribution notices cannot be construed
+          as modifying the License.
+
+      You may add Your own copyright statement to Your modifications and
+      may provide additional or different license terms and conditions
+      for use, reproduction, or distribution of Your modifications, or
+      for any such Derivative Works as a whole, provided Your use,
+      reproduction, and distribution of the Work otherwise complies with
+      the conditions stated in this License.
+
+   5. Submission of Contributions. Unless You explicitly state otherwise,
+      any Contribution intentionally submitted for inclusion in the Work
+      by You to the Licensor shall be under the terms and conditions of
+      this License, without any additional terms or conditions.
+      Notwithstanding the above, nothing herein shall supersede or modify
+      the terms of any separate license agreement you may have executed
+      with Licensor regarding such Contributions.
+
+   6. Trademarks. This License does not grant permission to use the trade
+      names, trademarks, service marks, or product names of the Licensor,
+      except as required for reasonable and customary use in describing the
+      origin of the Work and reproducing the content of the NOTICE file.
+
+   7. Disclaimer of Warranty. Unless required by applicable law or
+      agreed to in writing, Licensor provides the Work (and each
+      Contributor provides its Contributions) on an ""AS IS"" BASIS,
+      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
+      implied, including, without limitation, any warranties or conditions
+      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
+      PARTICULAR PURPOSE. You are solely responsible for determining the
+      appropriateness of using or redistributing the Work and assume any
+      risks associated with Your exercise of permissions under this License.
+
+   8. Limitation of Liability. In no event and under no legal theory,
+      whether in tort (including negligence), contract, or otherwise,
+      unless required by applicable law (such as deliberate and grossly
+      negligent acts) or agreed to in writing, shall any Contributor be
+      liable to You for damages, including any direct, indirect, special,
+      incidental, or consequential damages of any character arising as a
+      result of this License or out of the use or inability to use the
+      Work (including but not limited to damages for loss of goodwill,
+      work stoppage, computer failure or malfunction, or any and all
+      other commercial damages or losses), even if such Contributor
+      has been advised of the possibility of such damages.
+
+   9. Accepting Warranty or Additional Liability. While redistributing
+      the Work or Derivative Works thereof, You may choose to offer,
+      and charge a fee for, acceptance of support, warranty, indemnity,
+      or other liability obligations and/or rights consistent with this
+      License. However, in accepting such obligations, You may act only
+      on Your own behalf and on Your sole responsibility, not on behalf
+      of any other Contributor, and only if You agree to indemnify,
+      defend, and hold each Contributor harmless for any liability
+      incurred by, or claims asserted against, such Contributor by reason
+      of your accepting any such warranty or additional liability.
+
+   END OF TERMS AND CONDITIONS
+
+   APPENDIX: How to apply the Apache License to your work.
+
+      To apply the Apache License to your work, attach the following
+      boilerplate notice, with the fields enclosed by brackets ""[]""
+      replaced with your own identifying information. (Don't include
+      the brackets!)  The text should be enclosed in the appropriate
+      comment syntax for the file format. We also recommend that a
+      file or class name and description of purpose be included on the
+      same ""printed page"" as the copyright notice for easier
+      identification within third-party archives.
+
+   Copyright [yyyy] [name of copyright owner]
+
+   Licensed under the Apache License, Version 2.0 (the ""License"");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an ""AS IS"" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
\ No newline at end of file
","diff --git a/LICENSE b/LICENSE
new file mode 100644
index 0000000..7a4a3ea
--- /dev/null
+++ b/LICENSE
@@ -0,0 +1,202 @@
+
+                                 Apache License
+                           Version 2.0, January 2004
+                        http://www.apache.org/licenses/
+
+   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
+
+   1. Definitions.
+
+      ""License"" shall mean the terms and conditions for use, reproduction,
+      and distribution as defined by Sections 1 through 9 of this document.
+
+      ""Licensor"" shall mean the copyright owner or entity authorized by
+      the copyright owner that is granting the License.
+
+      ""Legal Entity"" shall mean the union of the acting entity and all
+      other entities that control, are controlled by, or are under common
+      control with that entity. For the purposes of this definition,
+      ""control"" means (i) the power, direct or indirect, to cause the
+      direction or management of such entity, whether by contract or
+      otherwise, or (ii) ownership of fifty percent (50%) or more of the
+      outstanding shares, or (iii) beneficial ownership of such entity.
+
+      ""You"" (or ""Your"") shall mean an individual or Legal Entity
+      exercising permissions granted by this License.
+
+      ""Source"" form shall mean the preferred form for making modifications,
+      including but not limited to software source code, documentation
+      source, and configuration files.
+
+      ""Object"" form shall mean any form resulting from mechanical
+      transformation or translation of a Source form, including but
+      not limited to compiled object code, generated documentation,
+      and conversions to other media types.
+
+      ""Work"" shall mean the work of authorship, whether in Source or
+      Object form, made available under the License, as indicated by a
+      copyright notice that is included in or attached to the work
+      (an example is provided in the Appendix below).
+
+      ""Derivative Works"" shall mean any work, whether in Source or Object
+      form, that is based on (or derived from) the Work and for which the
+      editorial revisions, annotations, elaborations, or other modifications
+      represent, as a whole, an original work of authorship. For the purposes
+      of this License, Derivative Works shall not include works that remain
+      separable from, or merely link (or bind by name) to the interfaces of,
+      the Work and Derivative Works thereof.
+
+      ""Contribution"" shall mean any work of authorship, including
+      the original version of the Work and any modifications or additions
+      to that Work or Derivative Works thereof, that is intentionally
+      submitted to Licensor for inclusion in the Work by the copyright owner
+      or by an individual or Legal Entity authorized to submit on behalf of
+      the copyright owner. For the purposes of this definition, ""submitted""
+      means any form of electronic, verbal, or written communication sent
+      to the Licensor or its representatives, including but not limited to
+      communication on electronic mailing lists, source code control systems,
+      and issue tracking systems that are managed by, or on behalf of, the
+      Licensor for the purpose of discussing and improving the Work, but
+      excluding communication that is conspicuously marked or otherwise
+      designated in writing by the copyright owner as ""Not a Contribution.""
+
+      ""Contributor"" shall mean Licensor and any individual or Legal Entity
+      on behalf of whom a Contribution has been received by Licensor and
+      subsequently incorporated within the Work.
+
+   2. Grant of Copyright License. Subject to the terms and conditions of
+      this License, each Contributor hereby grants to You a perpetual,
+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+      copyright license to reproduce, prepare Derivative Works of,
+      publicly display, publicly perform, sublicense, and distribute the
+      Work and such Derivative Works in Source or Object form.
+
+   3. Grant of Patent License. Subject to the terms and conditions of
+      this License, each Contributor hereby grants to You a perpetual,
+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+      (except as stated in this section) patent license to make, have made,
+      use, offer to sell, sell, import, and otherwise transfer the Work,
+      where such license applies only to those patent claims licensable
+      by such Contributor that are necessarily infringed by their
+      Contribution(s) alone or by combination of their Contribution(s)
+      with the Work to which such Contribution(s) was submitted. If You
+      institute patent litigation against any entity (including a
+      cross-claim or counterclaim in a lawsuit) alleging that the Work
+      or a Contribution incorporated within the Work constitutes direct
+      or contributory patent infringement, then any patent licenses
+      granted to You under this License for that Work shall terminate
+      as of the date such litigation is filed.
+
+   4. Redistribution. You may reproduce and distribute copies of the
+      Work or Derivative Works thereof in any medium, with or without
+      modifications, and in Source or Object form, provided that You
+      meet the following conditions:
+
+      (a) You must give any other recipients of the Work or
+          Derivative Works a copy of this License; and
+
+      (b) You must cause any modified files to carry prominent notices
+          stating that You changed the files; and
+
+      (c) You must retain, in the Source form of any Derivative Works
+          that You distribute, all copyright, patent, trademark, and
+          attribution notices from the Source form of the Work,
+          excluding those notices that do not pertain to any part of
+          the Derivative Works; and
+
+      (d) If the Work includes a ""NOTICE"" text file as part of its
+          distribution, then any Derivative Works that You distribute must
+          include a readable copy of the attribution notices contained
+          within such NOTICE file, excluding those notices that do not
+          pertain to any part of the Derivative Works, in at least one
+          of the following places: within a NOTICE text file distributed
+          as part of the Derivative Works; within the Source form or
+          documentation, if provided along with the Derivative Works; or,
+          within a display generated by the Derivative Works, if and
+          wherever such third-party notices normally appear. The contents
+          of the NOTICE file are for informational purposes only and
+          do not modify the License. You may add Your own attribution
+          notices within Derivative Works that You distribute, alongside
+          or as an addendum to the NOTICE text from the Work, provided
+          that such additional attribution notices cannot be construed
+          as modifying the License.
+
+      You may add Your own copyright statement to Your modifications and
+      may provide additional or different license terms and conditions
+      for use, reproduction, or distribution of Your modifications, or
+      for any such Derivative Works as a whole, provided Your use,
+      reproduction, and distribution of the Work otherwise complies with
+      the conditions stated in this License.
+
+   5. Submission of Contributions. Unless You explicitly state otherwise,
+      any Contribution intentionally submitted for inclusion in the Work
+      by You to the Licensor shall be under the terms and conditions of
+      this License, without any additional terms or conditions.
+      Notwithstanding the above, nothing herein shall supersede or modify
+      the terms of any separate license agreement you may have executed
+      with Licensor regarding such Contributions.
+
+   6. Trademarks. This License does not grant permission to use the trade
+      names, trademarks, service marks, or product names of the Licensor,
+      except as required for reasonable and customary use in describing the
+      origin of the Work and reproducing the content of the NOTICE file.
+
+   7. Disclaimer of Warranty. Unless required by applicable law or
+      agreed to in writing, Licensor provides the Work (and each
+      Contributor provides its Contributions) on an ""AS IS"" BASIS,
+      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
+      implied, including, without limitation, any warranties or conditions
+      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
+      PARTICULAR PURPOSE. You are solely responsible for determining the
+      appropriateness of using or redistributing the Work and assume any
+      risks associated with Your exercise of permissions under this License.
+
+   8. Limitation of Liability. In no event and under no legal theory,
+      whether in tort (including negligence), contract, or otherwise,
+      unless required by applicable law (such as deliberate and grossly
+      negligent acts) or agreed to in writing, shall any Contributor be
+      liable to You for damages, including any direct, indirect, special,
+      incidental, or consequential damages of any character arising as a
+      result of this License or out of the use or inability to use the
+      Work (including but not limited to damages for loss of goodwill,
+      work stoppage, computer failure or malfunction, or any and all
+      other commercial damages or losses), even if such Contributor
+      has been advised of the possibility of such damages.
+
+   9. Accepting Warranty or Additional Liability. While redistributing
+      the Work or Derivative Works thereof, You may choose to offer,
+      and charge a fee for, acceptance of support, warranty, indemnity,
+      or other liability obligations and/or rights consistent with this
+      License. However, in accepting such obligations, You may act only
+      on Your own behalf and on Your sole responsibility, not on behalf
+      of any other Contributor, and only if You agree to indemnify,
+      defend, and hold each Contributor harmless for any liability
+      incurred by, or claims asserted against, such Contributor by reason
+      of your accepting any such warranty or additional liability.
+
+   END OF TERMS AND CONDITIONS
+
+   APPENDIX: How to apply the Apache License to your work.
+
+      To apply the Apache License to your work, attach the following
+      boilerplate notice, with the fields enclosed by brackets ""[]""
+      replaced with your own identifying information. (Don't include
+      the brackets!)  The text should be enclosed in the appropriate
+      comment syntax for the file format. We also recommend that a
+      file or class name and description of purpose be included on the
+      same ""printed page"" as the copyright notice for easier
+      identification within third-party archives.
+
+   Copyright [yyyy] [name of copyright owner]
+
+   Licensed under the Apache License, Version 2.0 (the ""License"");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an ""AS IS"" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
\ No newline at end of file
",No,LICENSE
adk-python,tests/unittests/agents/test_llm_agent_callbacks.py,tests/unittests/agents/test_llm_agent_callbacks.py,794a70edcd68e838b698716f7ce540756f0c4594,f96cdc675cea2f75f3d9e89203353ead68c70579,Support async agent and model callbacks  PiperOrigin-RevId: 755542756,"diff --git a/tests/unittests/agents/test_llm_agent_callbacks.py b/tests/unittests/agents/test_llm_agent_callbacks.py
index 377e1cf..99a606e 100644
--- a/tests/unittests/agents/test_llm_agent_callbacks.py
+++ b/tests/unittests/agents/test_llm_agent_callbacks.py
@@ -56,10 +56,44 @@ class MockAfterModelCallback(BaseModel):
     )
 
 
+class MockAsyncBeforeModelCallback(BaseModel):
+  mock_response: str
+
+  async def __call__(
+      self,
+      callback_context: CallbackContext,
+      llm_request: LlmRequest,
+  ) -> LlmResponse:
+    return LlmResponse(
+        content=utils.ModelContent(
+            [types.Part.from_text(text=self.mock_response)]
+        )
+    )
+
+
+class MockAsyncAfterModelCallback(BaseModel):
+  mock_response: str
+
+  async def __call__(
+      self,
+      callback_context: CallbackContext,
+      llm_response: LlmResponse,
+  ) -> LlmResponse:
+    return LlmResponse(
+        content=utils.ModelContent(
+            [types.Part.from_text(text=self.mock_response)]
+        )
+    )
+
+
 def noop_callback(**kwargs) -> Optional[LlmResponse]:
   pass
 
 
+async def async_noop_callback(**kwargs) -> Optional[LlmResponse]:
+  pass
+
+
 @pytest.mark.asyncio
 async def test_before_model_callback():
   responses = ['model_response']
@@ -99,14 +133,14 @@ async def test_before_model_callback_noop():
 
 
 @pytest.mark.asyncio
-async def test_before_model_callback_end():
+async def test_after_model_callback():
   responses = ['model_response']
   mock_model = utils.MockModel.create(responses=responses)
   agent = Agent(
       name='root_agent',
       model=mock_model,
-      before_model_callback=MockBeforeModelCallback(
-          mock_response='before_model_callback',
+      after_model_callback=MockAfterModelCallback(
+          mock_response='after_model_callback'
       ),
   )
 
@@ -114,19 +148,19 @@ async def test_before_model_callback_end():
   assert utils.simplify_events(
       await runner.run_async_with_new_session('test')
   ) == [
-      ('root_agent', 'before_model_callback'),
+      ('root_agent', 'after_model_callback'),
   ]
 
 
 @pytest.mark.asyncio
-async def test_after_model_callback():
+async def test_async_before_model_callback():
   responses = ['model_response']
   mock_model = utils.MockModel.create(responses=responses)
   agent = Agent(
       name='root_agent',
       model=mock_model,
-      after_model_callback=MockAfterModelCallback(
-          mock_response='after_model_callback'
+      before_model_callback=MockAsyncBeforeModelCallback(
+          mock_response='async_before_model_callback'
       ),
   )
 
@@ -134,5 +168,43 @@ async def test_after_model_callback():
   assert utils.simplify_events(
       await runner.run_async_with_new_session('test')
   ) == [
-      ('root_agent', 'after_model_callback'),
+      ('root_agent', 'async_before_model_callback'),
+  ]
+
+
+@pytest.mark.asyncio
+async def test_async_before_model_callback_noop():
+  responses = ['model_response']
+  mock_model = utils.MockModel.create(responses=responses)
+  agent = Agent(
+      name='root_agent',
+      model=mock_model,
+      before_model_callback=async_noop_callback,
+  )
+
+  runner = utils.TestInMemoryRunner(agent)
+  assert utils.simplify_events(
+      await runner.run_async_with_new_session('test')
+  ) == [
+      ('root_agent', 'model_response'),
+  ]
+
+
+@pytest.mark.asyncio
+async def test_async_after_model_callback():
+  responses = ['model_response']
+  mock_model = utils.MockModel.create(responses=responses)
+  agent = Agent(
+      name='root_agent',
+      model=mock_model,
+      after_model_callback=MockAsyncAfterModelCallback(
+          mock_response='async_after_model_callback'
+      ),
+  )
+
+  runner = utils.TestInMemoryRunner(agent)
+  assert utils.simplify_events(
+      await runner.run_async_with_new_session('test')
+  ) == [
+      ('root_agent', 'async_after_model_callback'),
   ]
","diff --git a/tests/unittests/agents/test_llm_agent_callbacks.py b/tests/unittests/agents/test_llm_agent_callbacks.py
index 377e1cf..99a606e 100644
--- a/tests/unittests/agents/test_llm_agent_callbacks.py
+++ b/tests/unittests/agents/test_llm_agent_callbacks.py
@@ -56,10 +56,44 @@ class MockAfterModelCallback(BaseModel):
     )
 
 
+class MockAsyncBeforeModelCallback(BaseModel):
+  mock_response: str
+
+  async def __call__(
+      self,
+      callback_context: CallbackContext,
+      llm_request: LlmRequest,
+  ) -> LlmResponse:
+    return LlmResponse(
+        content=utils.ModelContent(
+            [types.Part.from_text(text=self.mock_response)]
+        )
+    )
+
+
+class MockAsyncAfterModelCallback(BaseModel):
+  mock_response: str
+
+  async def __call__(
+      self,
+      callback_context: CallbackContext,
+      llm_response: LlmResponse,
+  ) -> LlmResponse:
+    return LlmResponse(
+        content=utils.ModelContent(
+            [types.Part.from_text(text=self.mock_response)]
+        )
+    )
+
+
 def noop_callback(**kwargs) -> Optional[LlmResponse]:
   pass
 
 
+async def async_noop_callback(**kwargs) -> Optional[LlmResponse]:
+  pass
+
+
 @pytest.mark.asyncio
 async def test_before_model_callback():
   responses = ['model_response']
@@ -98,26 +132,6 @@ async def test_before_model_callback_noop():
   ]
 
 
-@pytest.mark.asyncio
-async def test_before_model_callback_end():
-  responses = ['model_response']
-  mock_model = utils.MockModel.create(responses=responses)
-  agent = Agent(
-      name='root_agent',
-      model=mock_model,
-      before_model_callback=MockBeforeModelCallback(
-          mock_response='before_model_callback',
-      ),
-  )
-
-  runner = utils.TestInMemoryRunner(agent)
-  assert utils.simplify_events(
-      await runner.run_async_with_new_session('test')
-  ) == [
-      ('root_agent', 'before_model_callback'),
-  ]
-
-
 @pytest.mark.asyncio
 async def test_after_model_callback():
   responses = ['model_response']
@@ -136,3 +150,61 @@ async def test_after_model_callback():
   ) == [
       ('root_agent', 'after_model_callback'),
   ]
+
+
+@pytest.mark.asyncio
+async def test_async_before_model_callback():
+  responses = ['model_response']
+  mock_model = utils.MockModel.create(responses=responses)
+  agent = Agent(
+      name='root_agent',
+      model=mock_model,
+      before_model_callback=MockAsyncBeforeModelCallback(
+          mock_response='async_before_model_callback'
+      ),
+  )
+
+  runner = utils.TestInMemoryRunner(agent)
+  assert utils.simplify_events(
+      await runner.run_async_with_new_session('test')
+  ) == [
+      ('root_agent', 'async_before_model_callback'),
+  ]
+
+
+@pytest.mark.asyncio
+async def test_async_before_model_callback_noop():
+  responses = ['model_response']
+  mock_model = utils.MockModel.create(responses=responses)
+  agent = Agent(
+      name='root_agent',
+      model=mock_model,
+      before_model_callback=async_noop_callback,
+  )
+
+  runner = utils.TestInMemoryRunner(agent)
+  assert utils.simplify_events(
+      await runner.run_async_with_new_session('test')
+  ) == [
+      ('root_agent', 'model_response'),
+  ]
+
+
+@pytest.mark.asyncio
+async def test_async_after_model_callback():
+  responses = ['model_response']
+  mock_model = utils.MockModel.create(responses=responses)
+  agent = Agent(
+      name='root_agent',
+      model=mock_model,
+      after_model_callback=MockAsyncAfterModelCallback(
+          mock_response='async_after_model_callback'
+      ),
+  )
+
+  runner = utils.TestInMemoryRunner(agent)
+  assert utils.simplify_events(
+      await runner.run_async_with_new_session('test')
+  ) == [
+      ('root_agent', 'async_after_model_callback'),
+  ]
",Yes,TEST
adk-python,,src/google/adk/agents/active_streaming_tool.py,98278201436cc7f642ede1b22407783e8c155b5e,f92478bd5c542c159e589e3603e70741c3677ab7,Agent Development Kit(ADK)  An easy-to-use and powerful framework to build AI agents.,"diff --git a/src/google/adk/agents/active_streaming_tool.py b/src/google/adk/agents/active_streaming_tool.py
new file mode 100644
index 0000000..e5499e0
--- /dev/null
+++ b/src/google/adk/agents/active_streaming_tool.py
@@ -0,0 +1,38 @@
+# Copyright 2025 Google LLC
+#
+# Licensed under the Apache License, Version 2.0 (the ""License"");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+from __future__ import annotations
+
+import asyncio
+from typing import Optional
+
+from pydantic import BaseModel
+from pydantic import ConfigDict
+
+from .live_request_queue import LiveRequestQueue
+
+
+class ActiveStreamingTool(BaseModel):
+  """"""Manages streaming tool related resources during invocation.""""""
+
+  model_config = ConfigDict(
+      arbitrary_types_allowed=True,
+      extra='forbid',
+  )
+
+  task: Optional[asyncio.Task] = None
+  """"""The active task of this streaming tool.""""""
+
+  stream: Optional[LiveRequestQueue] = None
+  """"""The active (input) streams of this streaming tool.""""""
","diff --git a/src/google/adk/agents/active_streaming_tool.py b/src/google/adk/agents/active_streaming_tool.py
new file mode 100644
index 0000000..e5499e0
--- /dev/null
+++ b/src/google/adk/agents/active_streaming_tool.py
@@ -0,0 +1,38 @@
+# Copyright 2025 Google LLC
+#
+# Licensed under the Apache License, Version 2.0 (the ""License"");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+from __future__ import annotations
+
+import asyncio
+from typing import Optional
+
+from pydantic import BaseModel
+from pydantic import ConfigDict
+
+from .live_request_queue import LiveRequestQueue
+
+
+class ActiveStreamingTool(BaseModel):
+  """"""Manages streaming tool related resources during invocation.""""""
+
+  model_config = ConfigDict(
+      arbitrary_types_allowed=True,
+      extra='forbid',
+  )
+
+  task: Optional[asyncio.Task] = None
+  """"""The active task of this streaming tool.""""""
+
+  stream: Optional[LiveRequestQueue] = None
+  """"""The active (input) streams of this streaming tool.""""""
",No,SOURCE
adk-python,,src/google/adk/__init__.py,98278201436cc7f642ede1b22407783e8c155b5e,f92478bd5c542c159e589e3603e70741c3677ab7,Agent Development Kit(ADK)  An easy-to-use and powerful framework to build AI agents.,"diff --git a/src/google/adk/__init__.py b/src/google/adk/__init__.py
new file mode 100644
index 0000000..f52f6e0
--- /dev/null
+++ b/src/google/adk/__init__.py
@@ -0,0 +1,20 @@
+# Copyright 2025 Google LLC
+#
+# Licensed under the Apache License, Version 2.0 (the ""License"");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+from . import version
+from .agents.llm_agent import Agent
+from .runners import Runner
+
+__version__ = version.__version__
+__all__ = [""Agent"", ""Runner""]
","diff --git a/src/google/adk/__init__.py b/src/google/adk/__init__.py
new file mode 100644
index 0000000..f52f6e0
--- /dev/null
+++ b/src/google/adk/__init__.py
@@ -0,0 +1,20 @@
+# Copyright 2025 Google LLC
+#
+# Licensed under the Apache License, Version 2.0 (the ""License"");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+from . import version
+from .agents.llm_agent import Agent
+from .runners import Runner
+
+__version__ = version.__version__
+__all__ = [""Agent"", ""Runner""]
",No,SOURCE
adk-python,assets/agent-development-kit.png,assets/agent-development-kit.png,98278201436cc7f642ede1b22407783e8c155b5e,f92478bd5c542c159e589e3603e70741c3677ab7,Agent Development Kit(ADK)  An easy-to-use and powerful framework to build AI agents.,"diff --git a/assets/agent-development-kit.png b/assets/agent-development-kit.png
new file mode 100644
index 0000000..9f967ca
Binary files /dev/null and b/assets/agent-development-kit.png differ
","diff --git a/assets/agent-development-kit.png b/assets/agent-development-kit.png
new file mode 100644
index 0000000..9f967ca
Binary files /dev/null and b/assets/agent-development-kit.png differ
",No,OTHER
adk-python,src/google/adk/tools/google_api_tool/google_api_tool_sets.py,src/google/adk/tools/google_api_tool/google_api_tool_sets.py,61d4be2d7675c3a8e0db098192b5c15dbc6234f2,290058eb05211ef531b1752c6290da3f365e4e73,No public description  PiperOrigin-RevId: 748777998,"diff --git a/src/google/adk/tools/google_api_tool/google_api_tool_sets.py b/src/google/adk/tools/google_api_tool/google_api_tool_sets.py
index a8e30c7..5b099d7 100644
--- a/src/google/adk/tools/google_api_tool/google_api_tool_sets.py
+++ b/src/google/adk/tools/google_api_tool/google_api_tool_sets.py
@@ -19,37 +19,94 @@ from .google_api_tool_set import GoogleApiToolSet
 
 logger = logging.getLogger(__name__)
 
-calendar_tool_set = GoogleApiToolSet.load_tool_set(
-    api_name=""calendar"",
-    api_version=""v3"",
-)
+_bigquery_tool_set = None
+_calendar_tool_set = None
+_gmail_tool_set = None
+_youtube_tool_set = None
+_slides_tool_set = None
+_sheets_tool_set = None
+_docs_tool_set = None
+
+
+def __getattr__(name):
+  """"""This method dynamically loads and returns GoogleApiToolSet instances for
 
-bigquery_tool_set = GoogleApiToolSet.load_tool_set(
+  various Google APIs. It uses a lazy loading approach, initializing each
+  tool set only when it is first requested. This avoids unnecessary loading
+  of tool sets that are not used in a given session.
+
+  Args:
+      name (str): The name of the tool set to retrieve (e.g.,
+        ""bigquery_tool_set"").
+
+  Returns:
+      GoogleApiToolSet: The requested tool set instance.
+
+  Raises:
+      AttributeError: If the requested tool set name is not recognized.
+  """"""
+  global _bigquery_tool_set, _calendar_tool_set, _gmail_tool_set, _youtube_tool_set, _slides_tool_set, _sheets_tool_set, _docs_tool_set
+
+  match name:
+    case ""bigquery_tool_set"":
+      if _bigquery_tool_set is None:
+        _bigquery_tool_set = GoogleApiToolSet.load_tool_set(
             api_name=""bigquery"",
             api_version=""v2"",
         )
 
-gmail_tool_set = GoogleApiToolSet.load_tool_set(
+      return _bigquery_tool_set
+
+    case ""calendar_tool_set"":
+      if _calendar_tool_set is None:
+        _calendar_tool_set = GoogleApiToolSet.load_tool_set(
+            api_name=""calendar"",
+            api_version=""v3"",
+        )
+
+      return _calendar_tool_set
+
+    case ""gmail_tool_set"":
+      if _gmail_tool_set is None:
+        _gmail_tool_set = GoogleApiToolSet.load_tool_set(
             api_name=""gmail"",
             api_version=""v1"",
         )
 
-youtube_tool_set = GoogleApiToolSet.load_tool_set(
+      return _gmail_tool_set
+
+    case ""youtube_tool_set"":
+      if _youtube_tool_set is None:
+        _youtube_tool_set = GoogleApiToolSet.load_tool_set(
             api_name=""youtube"",
             api_version=""v3"",
         )
 
-slides_tool_set = GoogleApiToolSet.load_tool_set(
+      return _youtube_tool_set
+
+    case ""slides_tool_set"":
+      if _slides_tool_set is None:
+        _slides_tool_set = GoogleApiToolSet.load_tool_set(
             api_name=""slides"",
             api_version=""v1"",
         )
 
-sheets_tool_set = GoogleApiToolSet.load_tool_set(
+      return _slides_tool_set
+
+    case ""sheets_tool_set"":
+      if _sheets_tool_set is None:
+        _sheets_tool_set = GoogleApiToolSet.load_tool_set(
             api_name=""sheets"",
             api_version=""v4"",
         )
 
-docs_tool_set = GoogleApiToolSet.load_tool_set(
+      return _sheets_tool_set
+
+    case ""docs_tool_set"":
+      if _docs_tool_set is None:
+        _docs_tool_set = GoogleApiToolSet.load_tool_set(
             api_name=""docs"",
             api_version=""v1"",
         )
+
+      return _docs_tool_set
","diff --git a/src/google/adk/tools/google_api_tool/google_api_tool_sets.py b/src/google/adk/tools/google_api_tool/google_api_tool_sets.py
index a8e30c7..5b099d7 100644
--- a/src/google/adk/tools/google_api_tool/google_api_tool_sets.py
+++ b/src/google/adk/tools/google_api_tool/google_api_tool_sets.py
@@ -19,37 +19,94 @@ from .google_api_tool_set import GoogleApiToolSet
 
 logger = logging.getLogger(__name__)
 
-calendar_tool_set = GoogleApiToolSet.load_tool_set(
-    api_name=""calendar"",
-    api_version=""v3"",
-)
+_bigquery_tool_set = None
+_calendar_tool_set = None
+_gmail_tool_set = None
+_youtube_tool_set = None
+_slides_tool_set = None
+_sheets_tool_set = None
+_docs_tool_set = None
 
-bigquery_tool_set = GoogleApiToolSet.load_tool_set(
+
+def __getattr__(name):
+  """"""This method dynamically loads and returns GoogleApiToolSet instances for
+
+  various Google APIs. It uses a lazy loading approach, initializing each
+  tool set only when it is first requested. This avoids unnecessary loading
+  of tool sets that are not used in a given session.
+
+  Args:
+      name (str): The name of the tool set to retrieve (e.g.,
+        ""bigquery_tool_set"").
+
+  Returns:
+      GoogleApiToolSet: The requested tool set instance.
+
+  Raises:
+      AttributeError: If the requested tool set name is not recognized.
+  """"""
+  global _bigquery_tool_set, _calendar_tool_set, _gmail_tool_set, _youtube_tool_set, _slides_tool_set, _sheets_tool_set, _docs_tool_set
+
+  match name:
+    case ""bigquery_tool_set"":
+      if _bigquery_tool_set is None:
+        _bigquery_tool_set = GoogleApiToolSet.load_tool_set(
             api_name=""bigquery"",
             api_version=""v2"",
         )
 
-gmail_tool_set = GoogleApiToolSet.load_tool_set(
+      return _bigquery_tool_set
+
+    case ""calendar_tool_set"":
+      if _calendar_tool_set is None:
+        _calendar_tool_set = GoogleApiToolSet.load_tool_set(
+            api_name=""calendar"",
+            api_version=""v3"",
+        )
+
+      return _calendar_tool_set
+
+    case ""gmail_tool_set"":
+      if _gmail_tool_set is None:
+        _gmail_tool_set = GoogleApiToolSet.load_tool_set(
             api_name=""gmail"",
             api_version=""v1"",
         )
 
-youtube_tool_set = GoogleApiToolSet.load_tool_set(
+      return _gmail_tool_set
+
+    case ""youtube_tool_set"":
+      if _youtube_tool_set is None:
+        _youtube_tool_set = GoogleApiToolSet.load_tool_set(
             api_name=""youtube"",
             api_version=""v3"",
         )
 
-slides_tool_set = GoogleApiToolSet.load_tool_set(
+      return _youtube_tool_set
+
+    case ""slides_tool_set"":
+      if _slides_tool_set is None:
+        _slides_tool_set = GoogleApiToolSet.load_tool_set(
             api_name=""slides"",
             api_version=""v1"",
         )
 
-sheets_tool_set = GoogleApiToolSet.load_tool_set(
+      return _slides_tool_set
+
+    case ""sheets_tool_set"":
+      if _sheets_tool_set is None:
+        _sheets_tool_set = GoogleApiToolSet.load_tool_set(
             api_name=""sheets"",
             api_version=""v4"",
         )
 
-docs_tool_set = GoogleApiToolSet.load_tool_set(
+      return _sheets_tool_set
+
+    case ""docs_tool_set"":
+      if _docs_tool_set is None:
+        _docs_tool_set = GoogleApiToolSet.load_tool_set(
             api_name=""docs"",
             api_version=""v1"",
         )
+
+      return _docs_tool_set
",Yes,SOURCE
adk-python,src/google/adk/memory/in_memory_memory_service.py,src/google/adk/memory/in_memory_memory_service.py,30947b48b869343e1f9fee1824888b0d15546874,825f5d4f2e4a10db9c87d278caeb37db4b9b7a8f,feat(memory)!: Uses the new MemoryEntry schema for all memory related components.  BREAKING CHANGE. This commit changes all memory related interface to using the newly introduced MemoryEntry class.  PiperOrigin-RevId: 758464887,"diff --git a/src/google/adk/memory/in_memory_memory_service.py b/src/google/adk/memory/in_memory_memory_service.py
index 1f15486..a49aca5 100644
--- a/src/google/adk/memory/in_memory_memory_service.py
+++ b/src/google/adk/memory/in_memory_memory_service.py
@@ -12,11 +12,31 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from ..events.event import Event
-from ..sessions.session import Session
+
+from __future__ import annotations
+
+import re
+from typing import TYPE_CHECKING
+
+from typing_extensions import override
+
+from . import _utils
 from .base_memory_service import BaseMemoryService
-from .base_memory_service import MemoryResult
 from .base_memory_service import SearchMemoryResponse
+from .memory_entry import MemoryEntry
+
+if TYPE_CHECKING:
+  from ..events.event import Event
+  from ..sessions.session import Session
+
+
+def _user_key(app_name: str, user_id: str):
+  return f'{app_name}/{user_id}'
+
+
+def _extract_words_lower(text: str) -> set[str]:
+  """"""Extracts words from a string and converts them to lowercase.""""""
+  return set([word.lower() for word in re.findall(r'[A-Za-z]+', text)])
 
 
 class InMemoryMemoryService(BaseMemoryService):
@@ -26,37 +46,49 @@ class InMemoryMemoryService(BaseMemoryService):
   """"""
 
   def __init__(self):
-    self.session_events: dict[str, list[Event]] = {}
-    """"""keys are app_name/user_id/session_id""""""
+    self._session_events: dict[str, dict[str, list[Event]]] = {}
+    """"""Keys are app_name/user_id, session_id. Values are session event lists.""""""
 
+  @override
   async def add_session_to_memory(self, session: Session):
-    key = f'{session.app_name}/{session.user_id}/{session.id}'
-    self.session_events[key] = [
-        event for event in session.events if event.content
+    user_key = _user_key(session.app_name, session.user_id)
+    self._session_events[user_key] = self._session_events.get(
+        _user_key(session.app_name, session.user_id), {}
+    )
+    self._session_events[user_key][session.id] = [
+        event
+        for event in session.events
+        if event.content and event.content.parts
     ]
 
+  @override
   async def search_memory(
       self, *, app_name: str, user_id: str, query: str
   ) -> SearchMemoryResponse:
-    """"""Prototyping purpose only.""""""
-    keywords = set(query.lower().split())
+    user_key = _user_key(app_name, user_id)
+    if user_key not in self._session_events:
+      return SearchMemoryResponse()
+
+    words_in_query = set(query.lower().split())
     response = SearchMemoryResponse()
-    for key, events in self.session_events.items():
-      if not key.startswith(f'{app_name}/{user_id}/'):
-        continue
-      matched_events = []
-      for event in events:
+
+    for session_events in self._session_events[user_key].values():
+      for event in session_events:
         if not event.content or not event.content.parts:
           continue
-        parts = event.content.parts
-        text = '\n'.join([part.text for part in parts if part.text]).lower()
-        for keyword in keywords:
-          if keyword in text:
-            matched_events.append(event)
-            break
-      if matched_events:
-        session_id = key.split('/')[-1]
+        words_in_event = _extract_words_lower(
+            ' '.join([part.text for part in event.content.parts if part.text])
+        )
+        if not words_in_event:
+          continue
+
+        if any(query_word in words_in_event for query_word in words_in_query):
           response.memories.append(
-            MemoryResult(session_id=session_id, events=matched_events)
+              MemoryEntry(
+                  content=event.content,
+                  author=event.author,
+                  timestamp=_utils.format_timestamp(event.timestamp),
               )
+          )
+
     return response
","diff --git a/src/google/adk/memory/in_memory_memory_service.py b/src/google/adk/memory/in_memory_memory_service.py
index 1f15486..a49aca5 100644
--- a/src/google/adk/memory/in_memory_memory_service.py
+++ b/src/google/adk/memory/in_memory_memory_service.py
@@ -12,11 +12,31 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
+
+from __future__ import annotations
+
+import re
+from typing import TYPE_CHECKING
+
+from typing_extensions import override
+
+from . import _utils
+from .base_memory_service import BaseMemoryService
+from .base_memory_service import SearchMemoryResponse
+from .memory_entry import MemoryEntry
+
+if TYPE_CHECKING:
   from ..events.event import Event
   from ..sessions.session import Session
-from .base_memory_service import BaseMemoryService
-from .base_memory_service import MemoryResult
-from .base_memory_service import SearchMemoryResponse
+
+
+def _user_key(app_name: str, user_id: str):
+  return f'{app_name}/{user_id}'
+
+
+def _extract_words_lower(text: str) -> set[str]:
+  """"""Extracts words from a string and converts them to lowercase.""""""
+  return set([word.lower() for word in re.findall(r'[A-Za-z]+', text)])
 
 
 class InMemoryMemoryService(BaseMemoryService):
@@ -26,37 +46,49 @@ class InMemoryMemoryService(BaseMemoryService):
   """"""
 
   def __init__(self):
-    self.session_events: dict[str, list[Event]] = {}
-    """"""keys are app_name/user_id/session_id""""""
+    self._session_events: dict[str, dict[str, list[Event]]] = {}
+    """"""Keys are app_name/user_id, session_id. Values are session event lists.""""""
 
+  @override
   async def add_session_to_memory(self, session: Session):
-    key = f'{session.app_name}/{session.user_id}/{session.id}'
-    self.session_events[key] = [
-        event for event in session.events if event.content
+    user_key = _user_key(session.app_name, session.user_id)
+    self._session_events[user_key] = self._session_events.get(
+        _user_key(session.app_name, session.user_id), {}
+    )
+    self._session_events[user_key][session.id] = [
+        event
+        for event in session.events
+        if event.content and event.content.parts
     ]
 
+  @override
   async def search_memory(
       self, *, app_name: str, user_id: str, query: str
   ) -> SearchMemoryResponse:
-    """"""Prototyping purpose only.""""""
-    keywords = set(query.lower().split())
+    user_key = _user_key(app_name, user_id)
+    if user_key not in self._session_events:
+      return SearchMemoryResponse()
+
+    words_in_query = set(query.lower().split())
     response = SearchMemoryResponse()
-    for key, events in self.session_events.items():
-      if not key.startswith(f'{app_name}/{user_id}/'):
-        continue
-      matched_events = []
-      for event in events:
+
+    for session_events in self._session_events[user_key].values():
+      for event in session_events:
         if not event.content or not event.content.parts:
           continue
-        parts = event.content.parts
-        text = '\n'.join([part.text for part in parts if part.text]).lower()
-        for keyword in keywords:
-          if keyword in text:
-            matched_events.append(event)
-            break
-      if matched_events:
-        session_id = key.split('/')[-1]
-        response.memories.append(
-            MemoryResult(session_id=session_id, events=matched_events)
+        words_in_event = _extract_words_lower(
+            ' '.join([part.text for part in event.content.parts if part.text])
         )
+        if not words_in_event:
+          continue
+
+        if any(query_word in words_in_event for query_word in words_in_query):
+          response.memories.append(
+              MemoryEntry(
+                  content=event.content,
+                  author=event.author,
+                  timestamp=_utils.format_timestamp(event.timestamp),
+              )
+          )
+
     return response
",Yes,SOURCE
adk-python,,src/google/adk/agents/base_agent.py,98278201436cc7f642ede1b22407783e8c155b5e,f92478bd5c542c159e589e3603e70741c3677ab7,Agent Development Kit(ADK)  An easy-to-use and powerful framework to build AI agents.,"diff --git a/src/google/adk/agents/base_agent.py b/src/google/adk/agents/base_agent.py
new file mode 100644
index 0000000..c47d9e3
--- /dev/null
+++ b/src/google/adk/agents/base_agent.py
@@ -0,0 +1,345 @@
+# Copyright 2025 Google LLC
+#
+# Licensed under the Apache License, Version 2.0 (the ""License"");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+from __future__ import annotations
+
+from typing import Any
+from typing import AsyncGenerator
+from typing import Callable
+from typing import final
+from typing import Optional
+from typing import TYPE_CHECKING
+
+from google.genai import types
+from opentelemetry import trace
+from pydantic import BaseModel
+from pydantic import ConfigDict
+from pydantic import Field
+from pydantic import field_validator
+from typing_extensions import override
+
+from ..events.event import Event
+from .callback_context import CallbackContext
+
+if TYPE_CHECKING:
+  from .invocation_context import InvocationContext
+
+tracer = trace.get_tracer('gcp.vertex.agent')
+
+BeforeAgentCallback = Callable[[CallbackContext], Optional[types.Content]]
+""""""Callback signature that is invoked before the agent run.
+
+Args:
+  callback_context: MUST be named 'callback_context' (enforced).
+
+Returns:
+  The content to return to the user. When set, the agent run will skipped and
+  the provided content will be returned to user.
+""""""
+
+AfterAgentCallback = Callable[[CallbackContext], Optional[types.Content]]
+""""""Callback signature that is invoked after the agent run.
+
+Args:
+  callback_context: MUST be named 'callback_context' (enforced).
+
+Returns:
+  The content to return to the user. When set, the agent run will skipped and
+  the provided content will be appended to event history as agent response.
+""""""
+
+
+class BaseAgent(BaseModel):
+  """"""Base class for all agents in Agent Development Kit.""""""
+
+  model_config = ConfigDict(
+      arbitrary_types_allowed=True,
+      extra='forbid',
+  )
+
+  name: str
+  """"""The agent's name.
+
+  Agent name must be a Python identifier and unique within the agent tree.
+  Agent name cannot be ""user"", since it's reserved for end-user's input.
+  """"""
+
+  description: str = ''
+  """"""Description about the agent's capability.
+
+  The model uses this to determine whether to delegate control to the agent.
+  One-line description is enough and preferred.
+  """"""
+
+  parent_agent: Optional[BaseAgent] = Field(default=None, init=False)
+  """"""The parent agent of this agent.
+
+  Note that an agent can ONLY be added as sub-agent once.
+
+  If you want to add one agent twice as sub-agent, consider to create two agent
+  instances with identical config, but with different name and add them to the
+  agent tree.
+  """"""
+  sub_agents: list[BaseAgent] = Field(default_factory=list)
+  """"""The sub-agents of this agent.""""""
+
+  before_agent_callback: Optional[BeforeAgentCallback] = None
+  """"""Callback signature that is invoked before the agent run.
+
+  Args:
+    callback_context: MUST be named 'callback_context' (enforced).
+
+  Returns:
+    The content to return to the user. When set, the agent run will skipped and
+    the provided content will be returned to user.
+  """"""
+  after_agent_callback: Optional[AfterAgentCallback] = None
+  """"""Callback signature that is invoked after the agent run.
+
+  Args:
+    callback_context: MUST be named 'callback_context' (enforced).
+
+  Returns:
+    The content to return to the user. When set, the agent run will skipped and
+    the provided content will be appended to event history as agent response.
+  """"""
+
+  @final
+  async def run_async(
+      self,
+      parent_context: InvocationContext,
+  ) -> AsyncGenerator[Event, None]:
+    """"""Entry method to run an agent via text-based conversaction.
+
+    Args:
+      parent_context: InvocationContext, the invocation context of the parent
+        agent.
+
+    Yields:
+      Event: the events generated by the agent.
+    """"""
+
+    with tracer.start_as_current_span(f'agent_run [{self.name}]'):
+      ctx = self._create_invocation_context(parent_context)
+
+      if event := self.__handle_before_agent_callback(ctx):
+        yield event
+      if ctx.end_invocation:
+        return
+
+      async for event in self._run_async_impl(ctx):
+        yield event
+
+      if ctx.end_invocation:
+        return
+
+      if event := self.__handle_after_agent_callback(ctx):
+        yield event
+
+  @final
+  async def run_live(
+      self,
+      parent_context: InvocationContext,
+  ) -> AsyncGenerator[Event, None]:
+    """"""Entry method to run an agent via video/audio-based conversaction.
+
+    Args:
+      parent_context: InvocationContext, the invocation context of the parent
+        agent.
+
+    Yields:
+      Event: the events generated by the agent.
+    """"""
+    with tracer.start_as_current_span(f'agent_run [{self.name}]'):
+      ctx = self._create_invocation_context(parent_context)
+      # TODO(hangfei): support before/after_agent_callback
+
+      async for event in self._run_live_impl(ctx):
+        yield event
+
+  async def _run_async_impl(
+      self, ctx: InvocationContext
+  ) -> AsyncGenerator[Event, None]:
+    """"""Core logic to run this agent via text-based conversaction.
+
+    Args:
+      ctx: InvocationContext, the invocation context for this agent.
+
+    Yields:
+      Event: the events generated by the agent.
+    """"""
+    raise NotImplementedError(
+        f'_run_async_impl for {type(self)} is not implemented.'
+    )
+    yield  # AsyncGenerator requires having at least one yield statement
+
+  async def _run_live_impl(
+      self, ctx: InvocationContext
+  ) -> AsyncGenerator[Event, None]:
+    """"""Core logic to run this agent via video/audio-based conversaction.
+
+    Args:
+      ctx: InvocationContext, the invocation context for this agent.
+
+    Yields:
+      Event: the events generated by the agent.
+    """"""
+    raise NotImplementedError(
+        f'_run_live_impl for {type(self)} is not implemented.'
+    )
+    yield  # AsyncGenerator requires having at least one yield statement
+
+  @property
+  def root_agent(self) -> BaseAgent:
+    """"""Gets the root agent of this agent.""""""
+    root_agent = self
+    while root_agent.parent_agent is not None:
+      root_agent = root_agent.parent_agent
+    return root_agent
+
+  def find_agent(self, name: str) -> Optional[BaseAgent]:
+    """"""Finds the agent with the given name in this agent and its descendants.
+
+    Args:
+      name: The name of the agent to find.
+
+    Returns:
+      The agent with the matching name, or None if no such agent is found.
+    """"""
+    if self.name == name:
+      return self
+    return self.find_sub_agent(name)
+
+  def find_sub_agent(self, name: str) -> Optional[BaseAgent]:
+    """"""Finds the agent with the given name in this agent's descendants.
+
+    Args:
+      name: The name of the agent to find.
+
+    Returns:
+      The agent with the matching name, or None if no such agent is found.
+    """"""
+    for sub_agent in self.sub_agents:
+      if result := sub_agent.find_agent(name):
+        return result
+    return None
+
+  def _create_invocation_context(
+      self, parent_context: InvocationContext
+  ) -> InvocationContext:
+    """"""Creates a new invocation context for this agent.""""""
+    invocation_context = parent_context.model_copy(update={'agent': self})
+    if parent_context.branch:
+      invocation_context.branch = f'{parent_context.branch}.{self.name}'
+    return invocation_context
+
+  def __handle_before_agent_callback(
+      self, ctx: InvocationContext
+  ) -> Optional[Event]:
+    """"""Runs the before_agent_callback if it exists.
+
+    Returns:
+      Optional[Event]: an event if callback provides content or changed state.
+    """"""
+    ret_event = None
+
+    if not isinstance(self.before_agent_callback, Callable):
+      return ret_event
+
+    callback_context = CallbackContext(ctx)
+    before_agent_callback_content = self.before_agent_callback(
+        callback_context=callback_context
+    )
+
+    if before_agent_callback_content:
+      ret_event = Event(
+          invocation_id=ctx.invocation_id,
+          author=self.name,
+          branch=ctx.branch,
+          content=before_agent_callback_content,
+          actions=callback_context._event_actions,
+      )
+      ctx.end_invocation = True
+      return ret_event
+
+    if callback_context.state.has_delta():
+      ret_event = Event(
+          invocation_id=ctx.invocation_id,
+          author=self.name,
+          branch=ctx.branch,
+          actions=callback_context._event_actions,
+      )
+
+    return ret_event
+
+  def __handle_after_agent_callback(
+      self, invocation_context: InvocationContext
+  ) -> Optional[Event]:
+    """"""Runs the after_agent_callback if it exists.
+
+    Returns:
+      Optional[Event]: an event if callback provides content or changed state.
+    """"""
+    ret_event = None
+
+    if not isinstance(self.after_agent_callback, Callable):
+      return ret_event
+
+    callback_context = CallbackContext(invocation_context)
+    after_agent_callback_content = self.after_agent_callback(
+        callback_context=callback_context
+    )
+
+    if after_agent_callback_content or callback_context.state.has_delta():
+      ret_event = Event(
+          invocation_id=invocation_context.invocation_id,
+          author=self.name,
+          branch=invocation_context.branch,
+          content=after_agent_callback_content,
+          actions=callback_context._event_actions,
+      )
+
+    return ret_event
+
+  @override
+  def model_post_init(self, __context: Any) -> None:
+    self.__set_parent_agent_for_sub_agents()
+
+  @field_validator('name', mode='after')
+  @classmethod
+  def __validate_name(cls, value: str):
+    if not value.isidentifier():
+      raise ValueError(
+          f'Found invalid agent name: `{value}`.'
+          ' Agent name must be a valid identifier. It should start with a'
+          ' letter (a-z, A-Z) or an underscore (_), and can only contain'
+          ' letters, digits (0-9), and underscores.'
+      )
+    if value == 'user':
+      raise ValueError(
+          ""Agent name cannot be `user`. `user` is reserved for end-user's""
+          ' input.'
+      )
+    return value
+
+  def __set_parent_agent_for_sub_agents(self) -> BaseAgent:
+    for sub_agent in self.sub_agents:
+      if sub_agent.parent_agent is not None:
+        raise ValueError(
+            f'Agent `{sub_agent.name}` already has a parent agent, current'
+            f' parent: `{sub_agent.parent_agent.name}`, trying to add:'
+            f' `{self.name}`'
+        )
+      sub_agent.parent_agent = self
+    return self
","diff --git a/src/google/adk/agents/base_agent.py b/src/google/adk/agents/base_agent.py
new file mode 100644
index 0000000..c47d9e3
--- /dev/null
+++ b/src/google/adk/agents/base_agent.py
@@ -0,0 +1,345 @@
+# Copyright 2025 Google LLC
+#
+# Licensed under the Apache License, Version 2.0 (the ""License"");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+from __future__ import annotations
+
+from typing import Any
+from typing import AsyncGenerator
+from typing import Callable
+from typing import final
+from typing import Optional
+from typing import TYPE_CHECKING
+
+from google.genai import types
+from opentelemetry import trace
+from pydantic import BaseModel
+from pydantic import ConfigDict
+from pydantic import Field
+from pydantic import field_validator
+from typing_extensions import override
+
+from ..events.event import Event
+from .callback_context import CallbackContext
+
+if TYPE_CHECKING:
+  from .invocation_context import InvocationContext
+
+tracer = trace.get_tracer('gcp.vertex.agent')
+
+BeforeAgentCallback = Callable[[CallbackContext], Optional[types.Content]]
+""""""Callback signature that is invoked before the agent run.
+
+Args:
+  callback_context: MUST be named 'callback_context' (enforced).
+
+Returns:
+  The content to return to the user. When set, the agent run will skipped and
+  the provided content will be returned to user.
+""""""
+
+AfterAgentCallback = Callable[[CallbackContext], Optional[types.Content]]
+""""""Callback signature that is invoked after the agent run.
+
+Args:
+  callback_context: MUST be named 'callback_context' (enforced).
+
+Returns:
+  The content to return to the user. When set, the agent run will skipped and
+  the provided content will be appended to event history as agent response.
+""""""
+
+
+class BaseAgent(BaseModel):
+  """"""Base class for all agents in Agent Development Kit.""""""
+
+  model_config = ConfigDict(
+      arbitrary_types_allowed=True,
+      extra='forbid',
+  )
+
+  name: str
+  """"""The agent's name.
+
+  Agent name must be a Python identifier and unique within the agent tree.
+  Agent name cannot be ""user"", since it's reserved for end-user's input.
+  """"""
+
+  description: str = ''
+  """"""Description about the agent's capability.
+
+  The model uses this to determine whether to delegate control to the agent.
+  One-line description is enough and preferred.
+  """"""
+
+  parent_agent: Optional[BaseAgent] = Field(default=None, init=False)
+  """"""The parent agent of this agent.
+
+  Note that an agent can ONLY be added as sub-agent once.
+
+  If you want to add one agent twice as sub-agent, consider to create two agent
+  instances with identical config, but with different name and add them to the
+  agent tree.
+  """"""
+  sub_agents: list[BaseAgent] = Field(default_factory=list)
+  """"""The sub-agents of this agent.""""""
+
+  before_agent_callback: Optional[BeforeAgentCallback] = None
+  """"""Callback signature that is invoked before the agent run.
+
+  Args:
+    callback_context: MUST be named 'callback_context' (enforced).
+
+  Returns:
+    The content to return to the user. When set, the agent run will skipped and
+    the provided content will be returned to user.
+  """"""
+  after_agent_callback: Optional[AfterAgentCallback] = None
+  """"""Callback signature that is invoked after the agent run.
+
+  Args:
+    callback_context: MUST be named 'callback_context' (enforced).
+
+  Returns:
+    The content to return to the user. When set, the agent run will skipped and
+    the provided content will be appended to event history as agent response.
+  """"""
+
+  @final
+  async def run_async(
+      self,
+      parent_context: InvocationContext,
+  ) -> AsyncGenerator[Event, None]:
+    """"""Entry method to run an agent via text-based conversaction.
+
+    Args:
+      parent_context: InvocationContext, the invocation context of the parent
+        agent.
+
+    Yields:
+      Event: the events generated by the agent.
+    """"""
+
+    with tracer.start_as_current_span(f'agent_run [{self.name}]'):
+      ctx = self._create_invocation_context(parent_context)
+
+      if event := self.__handle_before_agent_callback(ctx):
+        yield event
+      if ctx.end_invocation:
+        return
+
+      async for event in self._run_async_impl(ctx):
+        yield event
+
+      if ctx.end_invocation:
+        return
+
+      if event := self.__handle_after_agent_callback(ctx):
+        yield event
+
+  @final
+  async def run_live(
+      self,
+      parent_context: InvocationContext,
+  ) -> AsyncGenerator[Event, None]:
+    """"""Entry method to run an agent via video/audio-based conversaction.
+
+    Args:
+      parent_context: InvocationContext, the invocation context of the parent
+        agent.
+
+    Yields:
+      Event: the events generated by the agent.
+    """"""
+    with tracer.start_as_current_span(f'agent_run [{self.name}]'):
+      ctx = self._create_invocation_context(parent_context)
+      # TODO(hangfei): support before/after_agent_callback
+
+      async for event in self._run_live_impl(ctx):
+        yield event
+
+  async def _run_async_impl(
+      self, ctx: InvocationContext
+  ) -> AsyncGenerator[Event, None]:
+    """"""Core logic to run this agent via text-based conversaction.
+
+    Args:
+      ctx: InvocationContext, the invocation context for this agent.
+
+    Yields:
+      Event: the events generated by the agent.
+    """"""
+    raise NotImplementedError(
+        f'_run_async_impl for {type(self)} is not implemented.'
+    )
+    yield  # AsyncGenerator requires having at least one yield statement
+
+  async def _run_live_impl(
+      self, ctx: InvocationContext
+  ) -> AsyncGenerator[Event, None]:
+    """"""Core logic to run this agent via video/audio-based conversaction.
+
+    Args:
+      ctx: InvocationContext, the invocation context for this agent.
+
+    Yields:
+      Event: the events generated by the agent.
+    """"""
+    raise NotImplementedError(
+        f'_run_live_impl for {type(self)} is not implemented.'
+    )
+    yield  # AsyncGenerator requires having at least one yield statement
+
+  @property
+  def root_agent(self) -> BaseAgent:
+    """"""Gets the root agent of this agent.""""""
+    root_agent = self
+    while root_agent.parent_agent is not None:
+      root_agent = root_agent.parent_agent
+    return root_agent
+
+  def find_agent(self, name: str) -> Optional[BaseAgent]:
+    """"""Finds the agent with the given name in this agent and its descendants.
+
+    Args:
+      name: The name of the agent to find.
+
+    Returns:
+      The agent with the matching name, or None if no such agent is found.
+    """"""
+    if self.name == name:
+      return self
+    return self.find_sub_agent(name)
+
+  def find_sub_agent(self, name: str) -> Optional[BaseAgent]:
+    """"""Finds the agent with the given name in this agent's descendants.
+
+    Args:
+      name: The name of the agent to find.
+
+    Returns:
+      The agent with the matching name, or None if no such agent is found.
+    """"""
+    for sub_agent in self.sub_agents:
+      if result := sub_agent.find_agent(name):
+        return result
+    return None
+
+  def _create_invocation_context(
+      self, parent_context: InvocationContext
+  ) -> InvocationContext:
+    """"""Creates a new invocation context for this agent.""""""
+    invocation_context = parent_context.model_copy(update={'agent': self})
+    if parent_context.branch:
+      invocation_context.branch = f'{parent_context.branch}.{self.name}'
+    return invocation_context
+
+  def __handle_before_agent_callback(
+      self, ctx: InvocationContext
+  ) -> Optional[Event]:
+    """"""Runs the before_agent_callback if it exists.
+
+    Returns:
+      Optional[Event]: an event if callback provides content or changed state.
+    """"""
+    ret_event = None
+
+    if not isinstance(self.before_agent_callback, Callable):
+      return ret_event
+
+    callback_context = CallbackContext(ctx)
+    before_agent_callback_content = self.before_agent_callback(
+        callback_context=callback_context
+    )
+
+    if before_agent_callback_content:
+      ret_event = Event(
+          invocation_id=ctx.invocation_id,
+          author=self.name,
+          branch=ctx.branch,
+          content=before_agent_callback_content,
+          actions=callback_context._event_actions,
+      )
+      ctx.end_invocation = True
+      return ret_event
+
+    if callback_context.state.has_delta():
+      ret_event = Event(
+          invocation_id=ctx.invocation_id,
+          author=self.name,
+          branch=ctx.branch,
+          actions=callback_context._event_actions,
+      )
+
+    return ret_event
+
+  def __handle_after_agent_callback(
+      self, invocation_context: InvocationContext
+  ) -> Optional[Event]:
+    """"""Runs the after_agent_callback if it exists.
+
+    Returns:
+      Optional[Event]: an event if callback provides content or changed state.
+    """"""
+    ret_event = None
+
+    if not isinstance(self.after_agent_callback, Callable):
+      return ret_event
+
+    callback_context = CallbackContext(invocation_context)
+    after_agent_callback_content = self.after_agent_callback(
+        callback_context=callback_context
+    )
+
+    if after_agent_callback_content or callback_context.state.has_delta():
+      ret_event = Event(
+          invocation_id=invocation_context.invocation_id,
+          author=self.name,
+          branch=invocation_context.branch,
+          content=after_agent_callback_content,
+          actions=callback_context._event_actions,
+      )
+
+    return ret_event
+
+  @override
+  def model_post_init(self, __context: Any) -> None:
+    self.__set_parent_agent_for_sub_agents()
+
+  @field_validator('name', mode='after')
+  @classmethod
+  def __validate_name(cls, value: str):
+    if not value.isidentifier():
+      raise ValueError(
+          f'Found invalid agent name: `{value}`.'
+          ' Agent name must be a valid identifier. It should start with a'
+          ' letter (a-z, A-Z) or an underscore (_), and can only contain'
+          ' letters, digits (0-9), and underscores.'
+      )
+    if value == 'user':
+      raise ValueError(
+          ""Agent name cannot be `user`. `user` is reserved for end-user's""
+          ' input.'
+      )
+    return value
+
+  def __set_parent_agent_for_sub_agents(self) -> BaseAgent:
+    for sub_agent in self.sub_agents:
+      if sub_agent.parent_agent is not None:
+        raise ValueError(
+            f'Agent `{sub_agent.name}` already has a parent agent, current'
+            f' parent: `{sub_agent.parent_agent.name}`, trying to add:'
+            f' `{self.name}`'
+        )
+      sub_agent.parent_agent = self
+    return self
",No,SOURCE
adk-python,src/google/adk/cli/fast_api.py,src/google/adk/cli/fast_api.py,05a0c6b30787e5d5566160516ea8a16243a1030f,df0892a7b8a0e6393cdf4fc9431508215df966d0,Add 'get_eval_report' and 'list_eval_reports' endpoints.  PiperOrigin-RevId: 757936497,"diff --git a/src/google/adk/cli/fast_api.py b/src/google/adk/cli/fast_api.py
index 1cc7600..086d433 100644
--- a/src/google/adk/cli/fast_api.py
+++ b/src/google/adk/cli/fast_api.py
@@ -22,13 +22,13 @@ import os
 from pathlib import Path
 import re
 import sys
+import time
 import traceback
 import typing
 from typing import Any
 from typing import List
 from typing import Literal
 from typing import Optional
-from typing import Union
 
 import click
 from fastapi import FastAPI
@@ -71,8 +71,10 @@ from ..sessions.session import Session
 from ..sessions.vertex_ai_session_service import VertexAiSessionService
 from ..tools.base_toolset import BaseToolset
 from .cli_eval import EVAL_SESSION_ID_PREFIX
+from .cli_eval import EvalCaseResult
 from .cli_eval import EvalMetric
 from .cli_eval import EvalMetricResult
+from .cli_eval import EvalSetResult
 from .cli_eval import EvalStatus
 from .utils import create_empty_state
 from .utils import envs
@@ -81,6 +83,7 @@ from .utils import evals
 logger = logging.getLogger(__name__)
 
 _EVAL_SET_FILE_EXTENSION = "".evalset.json""
+_EVAL_SET_RESULT_FILE_EXTENSION = "".evalset_result.json""
 
 
 class ApiServerSpanExporter(export.SpanExporter):
@@ -137,10 +140,12 @@ class RunEvalResult(BaseModel):
       populate_by_name=True,
   )
 
+  eval_set_file: str
   eval_set_id: str
   eval_id: str
   final_eval_status: EvalStatus
   eval_metric_results: list[tuple[EvalMetric, EvalMetricResult]]
+  user_id: str
   session_id: str
 
 
@@ -484,24 +489,117 @@ def get_fast_api_app(
           ""Eval ids to run list is empty. We will all evals in the eval set.""
       )
     root_agent = await _get_root_agent_async(app_name)
-    return [
+    run_eval_results = []
+    eval_case_results = []
+    async for eval_result in run_evals(
+        eval_set_to_evals,
+        root_agent,
+        getattr(root_agent, ""reset_data"", None),
+        req.eval_metrics,
+        session_service=session_service,
+        artifact_service=artifact_service,
+    ):
+      run_eval_results.append(
           RunEvalResult(
               app_name=app_name,
+              eval_set_file=eval_result.eval_set_file,
               eval_set_id=eval_set_id,
               eval_id=eval_result.eval_id,
               final_eval_status=eval_result.final_eval_status,
               eval_metric_results=eval_result.eval_metric_results,
+              user_id=eval_result.user_id,
               session_id=eval_result.session_id,
           )
-        async for eval_result in run_evals(
-            eval_set_to_evals,
-            root_agent,
-            getattr(root_agent, ""reset_data"", None),
-            req.eval_metrics,
-            session_service=session_service,
-            artifact_service=artifact_service,
       )
+      session = session_service.get_session(
+          app_name=app_name,
+          user_id=eval_result.user_id,
+          session_id=eval_result.session_id,
+      )
+      eval_case_results.append(
+          EvalCaseResult(
+              eval_set_file=eval_result.eval_set_file,
+              eval_id=eval_result.eval_id,
+              final_eval_status=eval_result.final_eval_status,
+              eval_metric_results=eval_result.eval_metric_results,
+              session_id=eval_result.session_id,
+              session_details=session,
+              user_id=eval_result.user_id,
+          )
+      )
+
+    timestamp = time.time()
+    eval_set_result_name = app_name + ""_"" + eval_set_id + ""_"" + str(timestamp)
+    eval_set_result = EvalSetResult(
+        eval_set_result_id=eval_set_result_name,
+        eval_set_result_name=eval_set_result_name,
+        eval_set_id=eval_set_id,
+        eval_case_results=eval_case_results,
+        creation_timestamp=timestamp,
+    )
+
+    # Write eval result file, with eval_set_result_name.
+    app_eval_history_dir = os.path.join(
+        agent_dir, app_name, "".adk"", ""eval_history""
+    )
+    if not os.path.exists(app_eval_history_dir):
+      os.makedirs(app_eval_history_dir)
+    # Convert to json and write to file.
+    eval_set_result_json = eval_set_result.model_dump_json()
+    eval_set_result_file_path = os.path.join(
+        app_eval_history_dir,
+        eval_set_result_name + _EVAL_SET_RESULT_FILE_EXTENSION,
+    )
+    logger.info(""Writing eval result to file: %s"", eval_set_result_file_path)
+    with open(eval_set_result_file_path, ""w"") as f:
+      f.write(json.dumps(eval_set_result_json, indent=2))
+
+    return run_eval_results
+
+  @app.get(
+      ""/apps/{app_name}/eval_results/{eval_result_id}"",
+      response_model_exclude_none=True,
+  )
+  def get_eval_result(
+      app_name: str,
+      eval_result_id: str,
+  ) -> EvalSetResult:
+    """"""Gets the eval result for the given eval id.""""""
+    # Load the eval set file data
+    maybe_eval_result_file_path = (
+        os.path.join(
+            agent_dir, app_name, "".adk"", ""eval_history"", eval_result_id
+        )
+        + _EVAL_SET_RESULT_FILE_EXTENSION
+    )
+    if not os.path.exists(maybe_eval_result_file_path):
+      raise HTTPException(
+          status_code=404,
+          detail=f""Eval result `{eval_result_id}` not found."",
+      )
+    with open(maybe_eval_result_file_path, ""r"") as file:
+      eval_result_data = json.load(file)  # Load JSON into a list
+    try:
+      eval_result = EvalSetResult.model_validate_json(eval_result_data)
+      return eval_result
+    except ValidationError as e:
+      logger.exception(""get_eval_result validation error: %s"", e)
+
+  @app.get(
+      ""/apps/{app_name}/eval_results"",
+      response_model_exclude_none=True,
+  )
+  def list_eval_results(app_name: str) -> list[str]:
+    """"""Lists all eval results for the given app.""""""
+    app_eval_history_directory = os.path.join(
+        agent_dir, app_name, "".adk"", ""eval_history""
+    )
+    eval_result_files = [
+        file.removesuffix(_EVAL_SET_RESULT_FILE_EXTENSION)
+        for file in os.listdir(app_eval_history_directory)
+        if file.endswith(_EVAL_SET_RESULT_FILE_EXTENSION)
     ]
+    return eval_result_files
 
   @app.delete(""/apps/{app_name}/users/{user_id}/sessions/{session_id}"")
   def delete_session(app_name: str, user_id: str, session_id: str):
","diff --git a/src/google/adk/cli/fast_api.py b/src/google/adk/cli/fast_api.py
index 1cc7600..086d433 100644
--- a/src/google/adk/cli/fast_api.py
+++ b/src/google/adk/cli/fast_api.py
@@ -22,13 +22,13 @@ import os
 from pathlib import Path
 import re
 import sys
+import time
 import traceback
 import typing
 from typing import Any
 from typing import List
 from typing import Literal
 from typing import Optional
-from typing import Union
 
 import click
 from fastapi import FastAPI
@@ -71,8 +71,10 @@ from ..sessions.session import Session
 from ..sessions.vertex_ai_session_service import VertexAiSessionService
 from ..tools.base_toolset import BaseToolset
 from .cli_eval import EVAL_SESSION_ID_PREFIX
+from .cli_eval import EvalCaseResult
 from .cli_eval import EvalMetric
 from .cli_eval import EvalMetricResult
+from .cli_eval import EvalSetResult
 from .cli_eval import EvalStatus
 from .utils import create_empty_state
 from .utils import envs
@@ -81,6 +83,7 @@ from .utils import evals
 logger = logging.getLogger(__name__)
 
 _EVAL_SET_FILE_EXTENSION = "".evalset.json""
+_EVAL_SET_RESULT_FILE_EXTENSION = "".evalset_result.json""
 
 
 class ApiServerSpanExporter(export.SpanExporter):
@@ -137,10 +140,12 @@ class RunEvalResult(BaseModel):
       populate_by_name=True,
   )
 
+  eval_set_file: str
   eval_set_id: str
   eval_id: str
   final_eval_status: EvalStatus
   eval_metric_results: list[tuple[EvalMetric, EvalMetricResult]]
+  user_id: str
   session_id: str
 
 
@@ -484,15 +489,8 @@ def get_fast_api_app(
           ""Eval ids to run list is empty. We will all evals in the eval set.""
       )
     root_agent = await _get_root_agent_async(app_name)
-    return [
-        RunEvalResult(
-            app_name=app_name,
-            eval_set_id=eval_set_id,
-            eval_id=eval_result.eval_id,
-            final_eval_status=eval_result.final_eval_status,
-            eval_metric_results=eval_result.eval_metric_results,
-            session_id=eval_result.session_id,
-        )
+    run_eval_results = []
+    eval_case_results = []
     async for eval_result in run_evals(
         eval_set_to_evals,
         root_agent,
@@ -500,8 +498,108 @@ def get_fast_api_app(
         req.eval_metrics,
         session_service=session_service,
         artifact_service=artifact_service,
+    ):
+      run_eval_results.append(
+          RunEvalResult(
+              app_name=app_name,
+              eval_set_file=eval_result.eval_set_file,
+              eval_set_id=eval_set_id,
+              eval_id=eval_result.eval_id,
+              final_eval_status=eval_result.final_eval_status,
+              eval_metric_results=eval_result.eval_metric_results,
+              user_id=eval_result.user_id,
+              session_id=eval_result.session_id,
           )
+      )
+      session = session_service.get_session(
+          app_name=app_name,
+          user_id=eval_result.user_id,
+          session_id=eval_result.session_id,
+      )
+      eval_case_results.append(
+          EvalCaseResult(
+              eval_set_file=eval_result.eval_set_file,
+              eval_id=eval_result.eval_id,
+              final_eval_status=eval_result.final_eval_status,
+              eval_metric_results=eval_result.eval_metric_results,
+              session_id=eval_result.session_id,
+              session_details=session,
+              user_id=eval_result.user_id,
+          )
+      )
+
+    timestamp = time.time()
+    eval_set_result_name = app_name + ""_"" + eval_set_id + ""_"" + str(timestamp)
+    eval_set_result = EvalSetResult(
+        eval_set_result_id=eval_set_result_name,
+        eval_set_result_name=eval_set_result_name,
+        eval_set_id=eval_set_id,
+        eval_case_results=eval_case_results,
+        creation_timestamp=timestamp,
+    )
+
+    # Write eval result file, with eval_set_result_name.
+    app_eval_history_dir = os.path.join(
+        agent_dir, app_name, "".adk"", ""eval_history""
+    )
+    if not os.path.exists(app_eval_history_dir):
+      os.makedirs(app_eval_history_dir)
+    # Convert to json and write to file.
+    eval_set_result_json = eval_set_result.model_dump_json()
+    eval_set_result_file_path = os.path.join(
+        app_eval_history_dir,
+        eval_set_result_name + _EVAL_SET_RESULT_FILE_EXTENSION,
+    )
+    logger.info(""Writing eval result to file: %s"", eval_set_result_file_path)
+    with open(eval_set_result_file_path, ""w"") as f:
+      f.write(json.dumps(eval_set_result_json, indent=2))
+
+    return run_eval_results
+
+  @app.get(
+      ""/apps/{app_name}/eval_results/{eval_result_id}"",
+      response_model_exclude_none=True,
+  )
+  def get_eval_result(
+      app_name: str,
+      eval_result_id: str,
+  ) -> EvalSetResult:
+    """"""Gets the eval result for the given eval id.""""""
+    # Load the eval set file data
+    maybe_eval_result_file_path = (
+        os.path.join(
+            agent_dir, app_name, "".adk"", ""eval_history"", eval_result_id
+        )
+        + _EVAL_SET_RESULT_FILE_EXTENSION
+    )
+    if not os.path.exists(maybe_eval_result_file_path):
+      raise HTTPException(
+          status_code=404,
+          detail=f""Eval result `{eval_result_id}` not found."",
+      )
+    with open(maybe_eval_result_file_path, ""r"") as file:
+      eval_result_data = json.load(file)  # Load JSON into a list
+    try:
+      eval_result = EvalSetResult.model_validate_json(eval_result_data)
+      return eval_result
+    except ValidationError as e:
+      logger.exception(""get_eval_result validation error: %s"", e)
+
+  @app.get(
+      ""/apps/{app_name}/eval_results"",
+      response_model_exclude_none=True,
+  )
+  def list_eval_results(app_name: str) -> list[str]:
+    """"""Lists all eval results for the given app.""""""
+    app_eval_history_directory = os.path.join(
+        agent_dir, app_name, "".adk"", ""eval_history""
+    )
+    eval_result_files = [
+        file.removesuffix(_EVAL_SET_RESULT_FILE_EXTENSION)
+        for file in os.listdir(app_eval_history_directory)
+        if file.endswith(_EVAL_SET_RESULT_FILE_EXTENSION)
     ]
+    return eval_result_files
 
   @app.delete(""/apps/{app_name}/users/{user_id}/sessions/{session_id}"")
   def delete_session(app_name: str, user_id: str, session_id: str):
",Yes,SOURCE
adk-python,README.md,README.md,98278201436cc7f642ede1b22407783e8c155b5e,f92478bd5c542c159e589e3603e70741c3677ab7,Agent Development Kit(ADK)  An easy-to-use and powerful framework to build AI agents.,"diff --git a/README.md b/README.md
dissimilarity index 96%
index be6421a..5e228af 100644
--- a/README.md
+++ b/README.md
@@ -1,3 +1,95 @@
-# adk-python
-
-Hello World!
+# Agent Development Kit (ADK)
+
+[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](LICENSE)
+
+<img src=""assets/agent-development-kit.png"" alt=""Agent Development Kit Logo"" width=""150"">
+
+**An open-source, code-first Python toolkit for building, evaluating, and deploying sophisticated AI agents with flexibility and control.**
+
+The Agent Development Kit (ADK) is designed for developers seeking fine-grained control and flexibility when building advanced AI agents that are tightly integrated with services in Google Cloud. It allows you to define agent behavior, orchestration, and tool use directly in code, enabling robust debugging, versioning, and deployment anywhere – from your laptop to the cloud.
+
+---
+
+## ✨ Key Features
+
+* **Code-First Development:** Define agents, tools, and orchestration logic for maximum control, testability, and versioning.
+* **Multi-Agent Architecture:** Build modular and scalable applications by composing multiple specialized agents in flexible hierarchies.
+* **Rich Tool Ecosystem:** Equip agents with diverse capabilities using pre-built tools, custom Python functions, API specifications, or integrating existing tools.
+* **Flexible Orchestration:** Define workflows using built-in agents for predictable pipelines, or leverage LLM-driven dynamic routing for adaptive behavior.
+* **Integrated Developer Experience:** Develop, test, and debug locally with a CLI and visual web UI.
+* **Built-in Evaluation:** Measure agent performance by evaluating response quality and step-by-step execution trajectory.
+* **Deployment Ready:** Containerize and deploy your agents anywhere – scale with Vertex AI Agent Engine, Cloud Run, or Docker.
+* **Native Streaming Support:** Build real-time, interactive experiences with native support for bidirectional streaming (text and audio).
+* **State, Memory & Artifacts:** Manage short-term conversational context, configure long-term memory, and handle file uploads/downloads.
+* **Extensibility:** Customize agent behavior deeply with callbacks and easily integrate third-party tools and services.
+
+## 🚀 Installation
+
+You can install the Agent Developer Kit using `pip`:
+
+```bash
+pip install google-adk
+```
+
+## 🏁 Getting Started
+
+Create your first agent (`my_agent/agent.py`):
+
+```python
+# my_agent/agent.py
+from google.adk.agents import Agent
+from google.adk.tools import google_search
+
+root_agent = Agent(
+    name=""search_assistant"",
+    model=""gemini-1.5-flash-latest"", # Or your preferred model like gemini-2.0-flash-001
+    instruction=""You are a helpful assistant. Answer user questions using Google Search when needed."",
+    description=""An assistant that can search the web."",
+    tools=[google_search]
+)
+```
+
+Create `my_agent/__init__.py`:
+
+```python
+# my_agent/__init__.py
+from . import agent
+```
+
+Run it via the CLI (from the directory *containing* `my_agent`):
+
+```bash
+adk run my_agent
+```
+
+Or launch the Web UI from the folder that contains `my_agent` folder:
+
+```bash
+adk web
+```
+
+For a full step-by-step guide, check out the quickstart or sample agents.
+
+## 📚 Resources
+
+Explore the full documentation for detailed guides on building, evaluating, and deploying agents:
+
+*   **[Get Started](get-started/introduction.md)**
+*   **[Build Agents](build/agents.md)**
+*   **[Browse Sample Agents](learn/sample_agents/)**
+*   **[Evaluate Agents](evaluate/evaluate-agents.md)**
+*   **[Deploy Agents](deploy/overview.md)**
+*   **[API Reference](guides/reference.md)**
+*   **[Troubleshooting](guides/troubleshooting.md)**
+
+## 🤝 Contributing
+
+We welcome contributions from the community! Whether it's bug reports, feature requests, documentation improvements, or code contributions, please see our [**Contributing Guidelines**](./CONTRIBUTING.md) to get started.
+
+## 📄 License
+
+This project is licensed under the Apache 2.0 License - see the [LICENSE](LICENSE) file for details.
+
+---
+
+*Happy Agent Building!*
\ No newline at end of file
","diff --git a/README.md b/README.md
dissimilarity index 96%
index be6421a..5e228af 100644
--- a/README.md
+++ b/README.md
@@ -1,3 +1,95 @@
-# adk-python
-
-Hello World!
+# Agent Development Kit (ADK)
+
+[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](LICENSE)
+
+<img src=""assets/agent-development-kit.png"" alt=""Agent Development Kit Logo"" width=""150"">
+
+**An open-source, code-first Python toolkit for building, evaluating, and deploying sophisticated AI agents with flexibility and control.**
+
+The Agent Development Kit (ADK) is designed for developers seeking fine-grained control and flexibility when building advanced AI agents that are tightly integrated with services in Google Cloud. It allows you to define agent behavior, orchestration, and tool use directly in code, enabling robust debugging, versioning, and deployment anywhere – from your laptop to the cloud.
+
+---
+
+## ✨ Key Features
+
+* **Code-First Development:** Define agents, tools, and orchestration logic for maximum control, testability, and versioning.
+* **Multi-Agent Architecture:** Build modular and scalable applications by composing multiple specialized agents in flexible hierarchies.
+* **Rich Tool Ecosystem:** Equip agents with diverse capabilities using pre-built tools, custom Python functions, API specifications, or integrating existing tools.
+* **Flexible Orchestration:** Define workflows using built-in agents for predictable pipelines, or leverage LLM-driven dynamic routing for adaptive behavior.
+* **Integrated Developer Experience:** Develop, test, and debug locally with a CLI and visual web UI.
+* **Built-in Evaluation:** Measure agent performance by evaluating response quality and step-by-step execution trajectory.
+* **Deployment Ready:** Containerize and deploy your agents anywhere – scale with Vertex AI Agent Engine, Cloud Run, or Docker.
+* **Native Streaming Support:** Build real-time, interactive experiences with native support for bidirectional streaming (text and audio).
+* **State, Memory & Artifacts:** Manage short-term conversational context, configure long-term memory, and handle file uploads/downloads.
+* **Extensibility:** Customize agent behavior deeply with callbacks and easily integrate third-party tools and services.
+
+## 🚀 Installation
+
+You can install the Agent Developer Kit using `pip`:
+
+```bash
+pip install google-adk
+```
+
+## 🏁 Getting Started
+
+Create your first agent (`my_agent/agent.py`):
+
+```python
+# my_agent/agent.py
+from google.adk.agents import Agent
+from google.adk.tools import google_search
+
+root_agent = Agent(
+    name=""search_assistant"",
+    model=""gemini-1.5-flash-latest"", # Or your preferred model like gemini-2.0-flash-001
+    instruction=""You are a helpful assistant. Answer user questions using Google Search when needed."",
+    description=""An assistant that can search the web."",
+    tools=[google_search]
+)
+```
+
+Create `my_agent/__init__.py`:
+
+```python
+# my_agent/__init__.py
+from . import agent
+```
+
+Run it via the CLI (from the directory *containing* `my_agent`):
+
+```bash
+adk run my_agent
+```
+
+Or launch the Web UI from the folder that contains `my_agent` folder:
+
+```bash
+adk web
+```
+
+For a full step-by-step guide, check out the quickstart or sample agents.
+
+## 📚 Resources
+
+Explore the full documentation for detailed guides on building, evaluating, and deploying agents:
+
+*   **[Get Started](get-started/introduction.md)**
+*   **[Build Agents](build/agents.md)**
+*   **[Browse Sample Agents](learn/sample_agents/)**
+*   **[Evaluate Agents](evaluate/evaluate-agents.md)**
+*   **[Deploy Agents](deploy/overview.md)**
+*   **[API Reference](guides/reference.md)**
+*   **[Troubleshooting](guides/troubleshooting.md)**
+
+## 🤝 Contributing
+
+We welcome contributions from the community! Whether it's bug reports, feature requests, documentation improvements, or code contributions, please see our [**Contributing Guidelines**](./CONTRIBUTING.md) to get started.
+
+## 📄 License
+
+This project is licensed under the Apache 2.0 License - see the [LICENSE](LICENSE) file for details.
+
+---
+
+*Happy Agent Building!*
\ No newline at end of file
",No,README
adk-python,tests/unittests/tools/application_integration_tool/test_application_integration_toolset.py,tests/unittests/tools/application_integration_tool/test_application_integration_toolset.py,d740b93e037215f8fdffd2d84740db65c513dd6b,2d84b13219cb04062b76e738f0ac387e32b82062,feat: trigger in ApplicationIntegrationTools is changed to triggers and is a list of strings  PiperOrigin-RevId: 758034458,"diff --git a/tests/unittests/tools/application_integration_tool/test_application_integration_toolset.py b/tests/unittests/tools/application_integration_tool/test_application_integration_toolset.py
index 28dbb9d..0a707e6 100644
--- a/tests/unittests/tools/application_integration_tool/test_application_integration_toolset.py
+++ b/tests/unittests/tools/application_integration_tool/test_application_integration_toolset.py
@@ -52,6 +52,24 @@ def mock_openapi_toolset():
     yield mock_toolset
 
 
+@pytest.fixture
+def mock_openapi_toolset_with_multiple_tools_and_no_tools():
+  with mock.patch(
+      ""google.adk.tools.application_integration_tool.application_integration_toolset.OpenAPIToolset""
+  ) as mock_toolset:
+    mock_toolset_instance = mock.MagicMock()
+    mock_rest_api_tool = mock.MagicMock(spec=rest_api_tool.RestApiTool)
+    mock_rest_api_tool.name = ""Test Tool""
+    mock_rest_api_tool_2 = mock.MagicMock(spec=rest_api_tool.RestApiTool)
+    mock_rest_api_tool_2.name = ""Test Tool 2""
+    mock_toolset_instance.get_tools.return_value = [
+        mock_rest_api_tool,
+        mock_rest_api_tool_2,
+    ]
+    mock_toolset.return_value = mock_toolset_instance
+    yield mock_toolset
+
+
 def get_mocked_parsed_operation(operation_id, attributes):
   mock_openapi_spec_parser_instance = mock.MagicMock()
   mock_parsed_operation = mock.MagicMock(spec=ParsedOperation)
@@ -142,12 +160,12 @@ def test_initialization_with_integration_and_trigger(
     mock_openapi_toolset,
 ):
   integration_name = ""test-integration""
-  trigger_name = ""test-trigger""
+  triggers = [""test-trigger""]
   toolset = ApplicationIntegrationToolset(
-      project, location, integration=integration_name, trigger=trigger_name
+      project, location, integration=integration_name, triggers=triggers
   )
   mock_integration_client.assert_called_once_with(
-      project, location, integration_name, trigger_name, None, None, None, None
+      project, location, integration_name, triggers, None, None, None, None
   )
   mock_integration_client.return_value.get_openapi_spec_for_integration.assert_called_once()
   mock_connections_client.assert_not_called()
@@ -156,6 +174,58 @@ def test_initialization_with_integration_and_trigger(
   assert toolset.get_tools()[0].name == ""Test Tool""
 
 
+def test_initialization_with_integration_and_list_of_triggers(
+    project,
+    location,
+    mock_integration_client,
+    mock_connections_client,
+    mock_openapi_toolset_with_multiple_tools_and_no_tools,
+):
+  integration_name = ""test-integration""
+  triggers = [""test-trigger1"", ""test-trigger2""]
+  toolset = ApplicationIntegrationToolset(
+      project, location, integration=integration_name, triggers=triggers
+  )
+  mock_integration_client.assert_called_once_with(
+      project,
+      location,
+      integration_name,
+      triggers,
+      None,
+      None,
+      None,
+      None,
+  )
+  mock_integration_client.return_value.get_openapi_spec_for_integration.assert_called_once()
+  mock_connections_client.assert_not_called()
+  mock_openapi_toolset_with_multiple_tools_and_no_tools.assert_called_once()
+  assert len(toolset.get_tools()) == 2
+  assert toolset.get_tools()[0].name == ""Test Tool""
+  assert toolset.get_tools()[1].name == ""Test Tool 2""
+
+
+def test_initialization_with_integration_and_empty_trigger_list(
+    project,
+    location,
+    mock_integration_client,
+    mock_connections_client,
+    mock_openapi_toolset_with_multiple_tools_and_no_tools,
+):
+  integration_name = ""test-integration""
+  toolset = ApplicationIntegrationToolset(
+      project, location, integration=integration_name
+  )
+  mock_integration_client.assert_called_once_with(
+      project, location, integration_name, None, None, None, None, None
+  )
+  mock_integration_client.return_value.get_openapi_spec_for_integration.assert_called_once()
+  mock_connections_client.assert_not_called()
+  mock_openapi_toolset_with_multiple_tools_and_no_tools.assert_called_once()
+  assert len(toolset.get_tools()) == 2
+  assert toolset.get_tools()[0].name == ""Test Tool""
+  assert toolset.get_tools()[1].name == ""Test Tool 2""
+
+
 def test_initialization_with_connection_and_entity_operations(
     project,
     location,
@@ -250,7 +320,7 @@ def test_initialization_without_required_params(project, location):
   with pytest.raises(
       ValueError,
       match=(
-          ""Either \\(integration and trigger\\) or \\(connection and""
+          ""Invalid request, Either integration or \\(connection and""
           "" \\(entity_operations or actions\\)\\) should be provided.""
       ),
   ):
@@ -259,25 +329,16 @@ def test_initialization_without_required_params(project, location):
   with pytest.raises(
       ValueError,
       match=(
-          ""Either \\(integration and trigger\\) or \\(connection and""
-          "" \\(entity_operations or actions\\)\\) should be provided.""
-      ),
-  ):
-    ApplicationIntegrationToolset(project, location, integration=""test"")
-
-  with pytest.raises(
-      ValueError,
-      match=(
-          ""Either \\(integration and trigger\\) or \\(connection and""
+          ""Invalid request, Either integration or \\(connection and""
           "" \\(entity_operations or actions\\)\\) should be provided.""
       ),
   ):
-    ApplicationIntegrationToolset(project, location, trigger=""test"")
+    ApplicationIntegrationToolset(project, location, triggers=[""test""])
 
   with pytest.raises(
       ValueError,
       match=(
-          ""Either \\(integration and trigger\\) or \\(connection and""
+          ""Invalid request, Either integration or \\(connection and""
           "" \\(entity_operations or actions\\)\\) should be provided.""
       ),
   ):
@@ -305,19 +366,19 @@ def test_initialization_with_service_account_credentials(
       ""universe_domain"": ""googleapis.com"",
   })
   integration_name = ""test-integration""
-  trigger_name = ""test-trigger""
+  triggers = [""test-trigger""]
   toolset = ApplicationIntegrationToolset(
       project,
       location,
       integration=integration_name,
-      trigger=trigger_name,
+      triggers=triggers,
       service_account_json=service_account_json,
   )
   mock_integration_client.assert_called_once_with(
       project,
       location,
       integration_name,
-      trigger_name,
+      triggers,
       None,
       None,
       None,
@@ -338,12 +399,12 @@ def test_initialization_without_explicit_service_account_credentials(
     project, location, mock_integration_client, mock_openapi_toolset
 ):
   integration_name = ""test-integration""
-  trigger_name = ""test-trigger""
+  triggers = ""test-trigger""
   toolset = ApplicationIntegrationToolset(
-      project, location, integration=integration_name, trigger=trigger_name
+      project, location, integration=integration_name, triggers=triggers
   )
   mock_integration_client.assert_called_once_with(
-      project, location, integration_name, trigger_name, None, None, None, None
+      project, location, integration_name, triggers, None, None, None, None
   )
   mock_openapi_toolset.assert_called_once()
   _, kwargs = mock_openapi_toolset.call_args
@@ -355,9 +416,9 @@ def test_get_tools(
     project, location, mock_integration_client, mock_openapi_toolset
 ):
   integration_name = ""test-integration""
-  trigger_name = ""test-trigger""
+  triggers = [""test-trigger""]
   toolset = ApplicationIntegrationToolset(
-      project, location, integration=integration_name, trigger=trigger_name
+      project, location, integration=integration_name, triggers=triggers
   )
   tools = toolset.get_tools()
   assert len(tools) == 1
","diff --git a/tests/unittests/tools/application_integration_tool/test_application_integration_toolset.py b/tests/unittests/tools/application_integration_tool/test_application_integration_toolset.py
index 28dbb9d..0a707e6 100644
--- a/tests/unittests/tools/application_integration_tool/test_application_integration_toolset.py
+++ b/tests/unittests/tools/application_integration_tool/test_application_integration_toolset.py
@@ -52,6 +52,24 @@ def mock_openapi_toolset():
     yield mock_toolset
 
 
+@pytest.fixture
+def mock_openapi_toolset_with_multiple_tools_and_no_tools():
+  with mock.patch(
+      ""google.adk.tools.application_integration_tool.application_integration_toolset.OpenAPIToolset""
+  ) as mock_toolset:
+    mock_toolset_instance = mock.MagicMock()
+    mock_rest_api_tool = mock.MagicMock(spec=rest_api_tool.RestApiTool)
+    mock_rest_api_tool.name = ""Test Tool""
+    mock_rest_api_tool_2 = mock.MagicMock(spec=rest_api_tool.RestApiTool)
+    mock_rest_api_tool_2.name = ""Test Tool 2""
+    mock_toolset_instance.get_tools.return_value = [
+        mock_rest_api_tool,
+        mock_rest_api_tool_2,
+    ]
+    mock_toolset.return_value = mock_toolset_instance
+    yield mock_toolset
+
+
 def get_mocked_parsed_operation(operation_id, attributes):
   mock_openapi_spec_parser_instance = mock.MagicMock()
   mock_parsed_operation = mock.MagicMock(spec=ParsedOperation)
@@ -142,12 +160,12 @@ def test_initialization_with_integration_and_trigger(
     mock_openapi_toolset,
 ):
   integration_name = ""test-integration""
-  trigger_name = ""test-trigger""
+  triggers = [""test-trigger""]
   toolset = ApplicationIntegrationToolset(
-      project, location, integration=integration_name, trigger=trigger_name
+      project, location, integration=integration_name, triggers=triggers
   )
   mock_integration_client.assert_called_once_with(
-      project, location, integration_name, trigger_name, None, None, None, None
+      project, location, integration_name, triggers, None, None, None, None
   )
   mock_integration_client.return_value.get_openapi_spec_for_integration.assert_called_once()
   mock_connections_client.assert_not_called()
@@ -156,6 +174,58 @@ def test_initialization_with_integration_and_trigger(
   assert toolset.get_tools()[0].name == ""Test Tool""
 
 
+def test_initialization_with_integration_and_list_of_triggers(
+    project,
+    location,
+    mock_integration_client,
+    mock_connections_client,
+    mock_openapi_toolset_with_multiple_tools_and_no_tools,
+):
+  integration_name = ""test-integration""
+  triggers = [""test-trigger1"", ""test-trigger2""]
+  toolset = ApplicationIntegrationToolset(
+      project, location, integration=integration_name, triggers=triggers
+  )
+  mock_integration_client.assert_called_once_with(
+      project,
+      location,
+      integration_name,
+      triggers,
+      None,
+      None,
+      None,
+      None,
+  )
+  mock_integration_client.return_value.get_openapi_spec_for_integration.assert_called_once()
+  mock_connections_client.assert_not_called()
+  mock_openapi_toolset_with_multiple_tools_and_no_tools.assert_called_once()
+  assert len(toolset.get_tools()) == 2
+  assert toolset.get_tools()[0].name == ""Test Tool""
+  assert toolset.get_tools()[1].name == ""Test Tool 2""
+
+
+def test_initialization_with_integration_and_empty_trigger_list(
+    project,
+    location,
+    mock_integration_client,
+    mock_connections_client,
+    mock_openapi_toolset_with_multiple_tools_and_no_tools,
+):
+  integration_name = ""test-integration""
+  toolset = ApplicationIntegrationToolset(
+      project, location, integration=integration_name
+  )
+  mock_integration_client.assert_called_once_with(
+      project, location, integration_name, None, None, None, None, None
+  )
+  mock_integration_client.return_value.get_openapi_spec_for_integration.assert_called_once()
+  mock_connections_client.assert_not_called()
+  mock_openapi_toolset_with_multiple_tools_and_no_tools.assert_called_once()
+  assert len(toolset.get_tools()) == 2
+  assert toolset.get_tools()[0].name == ""Test Tool""
+  assert toolset.get_tools()[1].name == ""Test Tool 2""
+
+
 def test_initialization_with_connection_and_entity_operations(
     project,
     location,
@@ -250,7 +320,7 @@ def test_initialization_without_required_params(project, location):
   with pytest.raises(
       ValueError,
       match=(
-          ""Either \\(integration and trigger\\) or \\(connection and""
+          ""Invalid request, Either integration or \\(connection and""
           "" \\(entity_operations or actions\\)\\) should be provided.""
       ),
   ):
@@ -259,25 +329,16 @@ def test_initialization_without_required_params(project, location):
   with pytest.raises(
       ValueError,
       match=(
-          ""Either \\(integration and trigger\\) or \\(connection and""
+          ""Invalid request, Either integration or \\(connection and""
           "" \\(entity_operations or actions\\)\\) should be provided.""
       ),
   ):
-    ApplicationIntegrationToolset(project, location, integration=""test"")
+    ApplicationIntegrationToolset(project, location, triggers=[""test""])
 
   with pytest.raises(
       ValueError,
       match=(
-          ""Either \\(integration and trigger\\) or \\(connection and""
-          "" \\(entity_operations or actions\\)\\) should be provided.""
-      ),
-  ):
-    ApplicationIntegrationToolset(project, location, trigger=""test"")
-
-  with pytest.raises(
-      ValueError,
-      match=(
-          ""Either \\(integration and trigger\\) or \\(connection and""
+          ""Invalid request, Either integration or \\(connection and""
           "" \\(entity_operations or actions\\)\\) should be provided.""
       ),
   ):
@@ -305,19 +366,19 @@ def test_initialization_with_service_account_credentials(
       ""universe_domain"": ""googleapis.com"",
   })
   integration_name = ""test-integration""
-  trigger_name = ""test-trigger""
+  triggers = [""test-trigger""]
   toolset = ApplicationIntegrationToolset(
       project,
       location,
       integration=integration_name,
-      trigger=trigger_name,
+      triggers=triggers,
       service_account_json=service_account_json,
   )
   mock_integration_client.assert_called_once_with(
       project,
       location,
       integration_name,
-      trigger_name,
+      triggers,
       None,
       None,
       None,
@@ -338,12 +399,12 @@ def test_initialization_without_explicit_service_account_credentials(
     project, location, mock_integration_client, mock_openapi_toolset
 ):
   integration_name = ""test-integration""
-  trigger_name = ""test-trigger""
+  triggers = ""test-trigger""
   toolset = ApplicationIntegrationToolset(
-      project, location, integration=integration_name, trigger=trigger_name
+      project, location, integration=integration_name, triggers=triggers
   )
   mock_integration_client.assert_called_once_with(
-      project, location, integration_name, trigger_name, None, None, None, None
+      project, location, integration_name, triggers, None, None, None, None
   )
   mock_openapi_toolset.assert_called_once()
   _, kwargs = mock_openapi_toolset.call_args
@@ -355,9 +416,9 @@ def test_get_tools(
     project, location, mock_integration_client, mock_openapi_toolset
 ):
   integration_name = ""test-integration""
-  trigger_name = ""test-trigger""
+  triggers = [""test-trigger""]
   toolset = ApplicationIntegrationToolset(
-      project, location, integration=integration_name, trigger=trigger_name
+      project, location, integration=integration_name, triggers=triggers
   )
   tools = toolset.get_tools()
   assert len(tools) == 1
",Yes,TEST
adk-python,,CONTRIBUTING.md,98278201436cc7f642ede1b22407783e8c155b5e,f92478bd5c542c159e589e3603e70741c3677ab7,Agent Development Kit(ADK)  An easy-to-use and powerful framework to build AI agents.,"diff --git a/CONTRIBUTING.md b/CONTRIBUTING.md
new file mode 100644
index 0000000..bc23aae
--- /dev/null
+++ b/CONTRIBUTING.md
@@ -0,0 +1,33 @@
+# How to contribute
+
+We'd love to accept your patches and contributions to this project.
+
+## Before you begin
+
+### Sign our Contributor License Agreement
+
+Contributions to this project must be accompanied by a
+[Contributor License Agreement](https://cla.developers.google.com/about) (CLA).
+You (or your employer) retain the copyright to your contribution; this simply
+gives us permission to use and redistribute your contributions as part of the
+project.
+
+If you or your current employer have already signed the Google CLA (even if it
+was for a different project), you probably don't need to do it again.
+
+Visit <https://cla.developers.google.com/> to see your current agreements or to
+sign a new one.
+
+### Review our community guidelines
+
+This project follows
+[Google's Open Source Community Guidelines](https://opensource.google/conduct/).
+
+## Contribution process
+
+### Code reviews
+
+All submissions, including submissions by project members, require review. We
+use GitHub pull requests for this purpose. Consult
+[GitHub Help](https://help.github.com/articles/about-pull-requests/) for more
+information on using pull requests.
\ No newline at end of file
","diff --git a/CONTRIBUTING.md b/CONTRIBUTING.md
new file mode 100644
index 0000000..bc23aae
--- /dev/null
+++ b/CONTRIBUTING.md
@@ -0,0 +1,33 @@
+# How to contribute
+
+We'd love to accept your patches and contributions to this project.
+
+## Before you begin
+
+### Sign our Contributor License Agreement
+
+Contributions to this project must be accompanied by a
+[Contributor License Agreement](https://cla.developers.google.com/about) (CLA).
+You (or your employer) retain the copyright to your contribution; this simply
+gives us permission to use and redistribute your contributions as part of the
+project.
+
+If you or your current employer have already signed the Google CLA (even if it
+was for a different project), you probably don't need to do it again.
+
+Visit <https://cla.developers.google.com/> to see your current agreements or to
+sign a new one.
+
+### Review our community guidelines
+
+This project follows
+[Google's Open Source Community Guidelines](https://opensource.google/conduct/).
+
+## Contribution process
+
+### Code reviews
+
+All submissions, including submissions by project members, require review. We
+use GitHub pull requests for this purpose. Consult
+[GitHub Help](https://help.github.com/articles/about-pull-requests/) for more
+information on using pull requests.
\ No newline at end of file
",No,OTHER
adk-python,,pylintrc,98278201436cc7f642ede1b22407783e8c155b5e,f92478bd5c542c159e589e3603e70741c3677ab7,Agent Development Kit(ADK)  An easy-to-use and powerful framework to build AI agents.,"diff --git a/pylintrc b/pylintrc
new file mode 100644
index 0000000..d35fac3
--- /dev/null
+++ b/pylintrc
@@ -0,0 +1,400 @@
+# This Pylint rcfile contains a best-effort configuration to uphold the
+# best-practices and style described in the Google Python style guide:
+#   https://google.github.io/styleguide/pyguide.html
+#
+# Its canonical open-source location is:
+#   https://google.github.io/styleguide/pylintrc
+
+[MAIN]
+
+# Files or directories to be skipped. They should be base names, not paths.
+ignore=third_party
+
+# Files or directories matching the regex patterns are skipped. The regex
+# matches against base names, not paths.
+ignore-patterns=
+
+# Pickle collected data for later comparisons.
+persistent=no
+
+# List of plugins (as comma separated values of python modules names) to load,
+# usually to register additional checkers.
+load-plugins=
+
+# Use multiple processes to speed up Pylint.
+jobs=4
+
+# Allow loading of arbitrary C extensions. Extensions are imported into the
+# active Python interpreter and may run arbitrary code.
+unsafe-load-any-extension=no
+
+
+[MESSAGES CONTROL]
+
+# Only show warnings with the listed confidence levels. Leave empty to show
+# all. Valid levels: HIGH, INFERENCE, INFERENCE_FAILURE, UNDEFINED
+confidence=
+
+# Enable the message, report, category or checker with the given id(s). You can
+# either give multiple identifier separated by comma (,) or put this option
+# multiple time (only on the command line, not in the configuration file where
+# it should appear only once). See also the ""--disable"" option for examples.
+#enable=
+
+# Disable the message, report, category or checker with the given id(s). You
+# can either give multiple identifiers separated by comma (,) or put this
+# option multiple times (only on the command line, not in the configuration
+# file where it should appear only once).You can also use ""--disable=all"" to
+# disable everything first and then reenable specific checks. For example, if
+# you want to run only the similarities checker, you can use ""--disable=all
+# --enable=similarities"". If you want to run only the classes checker, but have
+# no Warning level messages displayed, use""--disable=all --enable=classes
+# --disable=W""
+disable=R,
+        abstract-method,
+        apply-builtin,
+        arguments-differ,
+        attribute-defined-outside-init,
+        backtick,
+        bad-option-value,
+        basestring-builtin,
+        buffer-builtin,
+        c-extension-no-member,
+        consider-using-enumerate,
+        cmp-builtin,
+        cmp-method,
+        coerce-builtin,
+        coerce-method,
+        delslice-method,
+        div-method,
+        eq-without-hash,
+        execfile-builtin,
+        file-builtin,
+        filter-builtin-not-iterating,
+        fixme,
+        getslice-method,
+        global-statement,
+        hex-method,
+        idiv-method,
+        implicit-str-concat,
+        import-error,
+        import-self,
+        import-star-module-level,
+        import-outside-toplevel,
+        input-builtin,
+        intern-builtin,
+        invalid-str-codec,
+        locally-disabled,
+        long-builtin,
+        long-suffix,
+        map-builtin-not-iterating,
+        misplaced-comparison-constant,
+        missing-function-docstring,
+        metaclass-assignment,
+        next-method-called,
+        next-method-defined,
+        no-absolute-import,
+        no-init,  # added
+        no-member,
+        no-name-in-module,
+        no-self-use,
+        nonzero-method,
+        oct-method,
+        old-division,
+        old-ne-operator,
+        old-octal-literal,
+        old-raise-syntax,
+        parameter-unpacking,
+        print-statement,
+        raising-string,
+        range-builtin-not-iterating,
+        raw_input-builtin,
+        rdiv-method,
+        reduce-builtin,
+        relative-import,
+        reload-builtin,
+        round-builtin,
+        setslice-method,
+        signature-differs,
+        standarderror-builtin,
+        suppressed-message,
+        sys-max-int,
+        trailing-newlines,
+        unichr-builtin,
+        unicode-builtin,
+        unnecessary-pass,
+        unpacking-in-except,
+        useless-else-on-loop,
+        useless-suppression,
+        using-cmp-argument,
+        wrong-import-order,
+        xrange-builtin,
+        zip-builtin-not-iterating,
+
+
+[REPORTS]
+
+# Set the output format. Available formats are text, parseable, colorized, msvs
+# (visual studio) and html. You can also give a reporter class, eg
+# mypackage.mymodule.MyReporterClass.
+output-format=text
+
+# Tells whether to display a full report or only the messages
+reports=no
+
+# Python expression which should return a note less than 10 (10 is the highest
+# note). You have access to the variables errors warning, statement which
+# respectively contain the number of errors / warnings messages and the total
+# number of statements analyzed. This is used by the global evaluation report
+# (RP0004).
+evaluation=10.0 - ((float(5 * error + warning + refactor + convention) / statement) * 10)
+
+# Template used to display messages. This is a python new-style format string
+# used to format the message information. See doc for all details
+#msg-template=
+
+
+[BASIC]
+
+# Good variable names which should always be accepted, separated by a comma
+good-names=main,_
+
+# Bad variable names which should always be refused, separated by a comma
+bad-names=
+
+# Colon-delimited sets of names that determine each other's naming style when
+# the name regexes allow several styles.
+name-group=
+
+# Include a hint for the correct naming format with invalid-name
+include-naming-hint=no
+
+# List of decorators that produce properties, such as abc.abstractproperty. Add
+# to this list to register other decorators that produce valid properties.
+property-classes=abc.abstractproperty,cached_property.cached_property,cached_property.threaded_cached_property,cached_property.cached_property_with_ttl,cached_property.threaded_cached_property_with_ttl
+
+# Regular expression matching correct function names
+function-rgx=^(?:(?P<exempt>setUp|tearDown|setUpModule|tearDownModule)|(?P<camel_case>_?[A-Z][a-zA-Z0-9]*)|(?P<snake_case>_?[a-z][a-z0-9_]*))$
+
+# Regular expression matching correct variable names
+variable-rgx=^[a-z][a-z0-9_]*$
+
+# Regular expression matching correct constant names
+const-rgx=^(_?[A-Z][A-Z0-9_]*|__[a-z0-9_]+__|_?[a-z][a-z0-9_]*)$
+
+# Regular expression matching correct attribute names
+attr-rgx=^_{0,2}[a-z][a-z0-9_]*$
+
+# Regular expression matching correct argument names
+argument-rgx=^[a-z][a-z0-9_]*$
+
+# Regular expression matching correct class attribute names
+class-attribute-rgx=^(_?[A-Z][A-Z0-9_]*|__[a-z0-9_]+__|_?[a-z][a-z0-9_]*)$
+
+# Regular expression matching correct inline iteration names
+inlinevar-rgx=^[a-z][a-z0-9_]*$
+
+# Regular expression matching correct class names
+class-rgx=^_?[A-Z][a-zA-Z0-9]*$
+
+# Regular expression matching correct module names
+module-rgx=^(_?[a-z][a-z0-9_]*|__init__)$
+
+# Regular expression matching correct method names
+method-rgx=(?x)^(?:(?P<exempt>_[a-z0-9_]+__|runTest|setUp|tearDown|setUpTestCase|tearDownTestCase|setupSelf|tearDownClass|setUpClass|(test|assert)_*[A-Z0-9][a-zA-Z0-9_]*|next)|(?P<camel_case>_{0,2}[A-Z][a-zA-Z0-9_]*)|(?P<snake_case>_{0,2}[a-z][a-z0-9_]*))$
+
+# Regular expression which should only match function or class names that do
+# not require a docstring.
+no-docstring-rgx=(__.*__|main|test.*|.*test|.*Test)$
+
+# Minimum line length for functions/classes that require docstrings, shorter
+# ones are exempt.
+docstring-min-length=12
+
+
+[TYPECHECK]
+
+# List of decorators that produce context managers, such as
+# contextlib.contextmanager. Add to this list to register other decorators that
+# produce valid context managers.
+contextmanager-decorators=contextlib.contextmanager,contextlib2.contextmanager
+
+# List of module names for which member attributes should not be checked
+# (useful for modules/projects where namespaces are manipulated during runtime
+# and thus existing member attributes cannot be deduced by static analysis. It
+# supports qualified module names, as well as Unix pattern matching.
+ignored-modules=
+
+# List of class names for which member attributes should not be checked (useful
+# for classes with dynamically set attributes). This supports the use of
+# qualified names.
+ignored-classes=optparse.Values,thread._local,_thread._local
+
+# List of members which are set dynamically and missed by pylint inference
+# system, and so shouldn't trigger E1101 when accessed. Python regular
+# expressions are accepted.
+generated-members=
+
+
+[FORMAT]
+
+# Maximum number of characters on a single line.
+max-line-length=80
+
+# TODO(https://github.com/pylint-dev/pylint/issues/3352): Direct pylint to exempt
+# lines made too long by directives to pytype.
+
+# Regexp for a line that is allowed to be longer than the limit.
+ignore-long-lines=(?x)(
+  ^\s*(\#\ )?<?https?://\S+>?$|
+  ^\s*(from\s+\S+\s+)?import\s+.+$)
+
+# Allow the body of an if to be on the same line as the test if there is no
+# else.
+single-line-if-stmt=yes
+
+# Maximum number of lines in a module
+max-module-lines=99999
+
+# String used as indentation unit.  The internal Google style guide mandates 2
+# spaces.  Google's externaly-published style guide says 4, consistent with
+# PEP 8.  Here, we use 2 spaces, for conformity with many open-sourced Google
+# projects (like TensorFlow).
+indent-string='  '
+
+# Number of spaces of indent required inside a hanging  or continued line.
+indent-after-paren=4
+
+# Expected format of line ending, e.g. empty (any line ending), LF or CRLF.
+expected-line-ending-format=
+
+
+[MISCELLANEOUS]
+
+# List of note tags to take in consideration, separated by a comma.
+notes=TODO
+
+
+[STRING]
+
+# This flag controls whether inconsistent-quotes generates a warning when the
+# character used as a quote delimiter is used inconsistently within a module.
+check-quote-consistency=yes
+
+
+[VARIABLES]
+
+# Tells whether we should check for unused import in __init__ files.
+init-import=no
+
+# A regular expression matching the name of dummy variables (i.e. expectedly
+# not used).
+dummy-variables-rgx=^\*{0,2}(_$|unused_|dummy_)
+
+# List of additional names supposed to be defined in builtins. Remember that
+# you should avoid to define new builtins when possible.
+additional-builtins=
+
+# List of strings which can identify a callback function by name. A callback
+# name must start or end with one of those strings.
+callbacks=cb_,_cb
+
+# List of qualified module names which can have objects that can redefine
+# builtins.
+redefining-builtins-modules=six,six.moves,past.builtins,future.builtins,functools
+
+
+[LOGGING]
+
+# Logging modules to check that the string format arguments are in logging
+# function parameter format
+logging-modules=logging,absl.logging,tensorflow.io.logging
+
+
+[SIMILARITIES]
+
+# Minimum lines number of a similarity.
+min-similarity-lines=4
+
+# Ignore comments when computing similarities.
+ignore-comments=yes
+
+# Ignore docstrings when computing similarities.
+ignore-docstrings=yes
+
+# Ignore imports when computing similarities.
+ignore-imports=no
+
+
+[SPELLING]
+
+# Spelling dictionary name. Available dictionaries: none. To make it working
+# install python-enchant package.
+spelling-dict=
+
+# List of comma separated words that should not be checked.
+spelling-ignore-words=
+
+# A path to a file that contains private dictionary; one word per line.
+spelling-private-dict-file=
+
+# Tells whether to store unknown words to indicated private dictionary in
+# --spelling-private-dict-file option instead of raising a message.
+spelling-store-unknown-words=no
+
+
+[IMPORTS]
+
+# Deprecated modules which should not be used, separated by a comma
+deprecated-modules=regsub,
+                   TERMIOS,
+                   Bastion,
+                   rexec,
+                   sets
+
+# Create a graph of every (i.e. internal and external) dependencies in the
+# given file (report RP0402 must not be disabled)
+import-graph=
+
+# Create a graph of external dependencies in the given file (report RP0402 must
+# not be disabled)
+ext-import-graph=
+
+# Create a graph of internal dependencies in the given file (report RP0402 must
+# not be disabled)
+int-import-graph=
+
+# Force import order to recognize a module as part of the standard
+# compatibility libraries.
+known-standard-library=
+
+# Force import order to recognize a module as part of a third party library.
+known-third-party=enchant, absl
+
+# Analyse import fallback blocks. This can be used to support both Python 2 and
+# 3 compatible code, which means that the block might have code that exists
+# only in one or another interpreter, leading to false positives when analysed.
+analyse-fallback-blocks=no
+
+
+[CLASSES]
+
+# List of method names used to declare (i.e. assign) instance attributes.
+defining-attr-methods=__init__,
+                      __new__,
+                      setUp
+
+# List of member names, which should be excluded from the protected access
+# warning.
+exclude-protected=_asdict,
+                  _fields,
+                  _replace,
+                  _source,
+                  _make
+
+# List of valid names for the first argument in a class method.
+valid-classmethod-first-arg=cls,
+                            class_
+
+# List of valid names for the first argument in a metaclass class method.
+valid-metaclass-classmethod-first-arg=mcs
","diff --git a/pylintrc b/pylintrc
new file mode 100644
index 0000000..d35fac3
--- /dev/null
+++ b/pylintrc
@@ -0,0 +1,400 @@
+# This Pylint rcfile contains a best-effort configuration to uphold the
+# best-practices and style described in the Google Python style guide:
+#   https://google.github.io/styleguide/pyguide.html
+#
+# Its canonical open-source location is:
+#   https://google.github.io/styleguide/pylintrc
+
+[MAIN]
+
+# Files or directories to be skipped. They should be base names, not paths.
+ignore=third_party
+
+# Files or directories matching the regex patterns are skipped. The regex
+# matches against base names, not paths.
+ignore-patterns=
+
+# Pickle collected data for later comparisons.
+persistent=no
+
+# List of plugins (as comma separated values of python modules names) to load,
+# usually to register additional checkers.
+load-plugins=
+
+# Use multiple processes to speed up Pylint.
+jobs=4
+
+# Allow loading of arbitrary C extensions. Extensions are imported into the
+# active Python interpreter and may run arbitrary code.
+unsafe-load-any-extension=no
+
+
+[MESSAGES CONTROL]
+
+# Only show warnings with the listed confidence levels. Leave empty to show
+# all. Valid levels: HIGH, INFERENCE, INFERENCE_FAILURE, UNDEFINED
+confidence=
+
+# Enable the message, report, category or checker with the given id(s). You can
+# either give multiple identifier separated by comma (,) or put this option
+# multiple time (only on the command line, not in the configuration file where
+# it should appear only once). See also the ""--disable"" option for examples.
+#enable=
+
+# Disable the message, report, category or checker with the given id(s). You
+# can either give multiple identifiers separated by comma (,) or put this
+# option multiple times (only on the command line, not in the configuration
+# file where it should appear only once).You can also use ""--disable=all"" to
+# disable everything first and then reenable specific checks. For example, if
+# you want to run only the similarities checker, you can use ""--disable=all
+# --enable=similarities"". If you want to run only the classes checker, but have
+# no Warning level messages displayed, use""--disable=all --enable=classes
+# --disable=W""
+disable=R,
+        abstract-method,
+        apply-builtin,
+        arguments-differ,
+        attribute-defined-outside-init,
+        backtick,
+        bad-option-value,
+        basestring-builtin,
+        buffer-builtin,
+        c-extension-no-member,
+        consider-using-enumerate,
+        cmp-builtin,
+        cmp-method,
+        coerce-builtin,
+        coerce-method,
+        delslice-method,
+        div-method,
+        eq-without-hash,
+        execfile-builtin,
+        file-builtin,
+        filter-builtin-not-iterating,
+        fixme,
+        getslice-method,
+        global-statement,
+        hex-method,
+        idiv-method,
+        implicit-str-concat,
+        import-error,
+        import-self,
+        import-star-module-level,
+        import-outside-toplevel,
+        input-builtin,
+        intern-builtin,
+        invalid-str-codec,
+        locally-disabled,
+        long-builtin,
+        long-suffix,
+        map-builtin-not-iterating,
+        misplaced-comparison-constant,
+        missing-function-docstring,
+        metaclass-assignment,
+        next-method-called,
+        next-method-defined,
+        no-absolute-import,
+        no-init,  # added
+        no-member,
+        no-name-in-module,
+        no-self-use,
+        nonzero-method,
+        oct-method,
+        old-division,
+        old-ne-operator,
+        old-octal-literal,
+        old-raise-syntax,
+        parameter-unpacking,
+        print-statement,
+        raising-string,
+        range-builtin-not-iterating,
+        raw_input-builtin,
+        rdiv-method,
+        reduce-builtin,
+        relative-import,
+        reload-builtin,
+        round-builtin,
+        setslice-method,
+        signature-differs,
+        standarderror-builtin,
+        suppressed-message,
+        sys-max-int,
+        trailing-newlines,
+        unichr-builtin,
+        unicode-builtin,
+        unnecessary-pass,
+        unpacking-in-except,
+        useless-else-on-loop,
+        useless-suppression,
+        using-cmp-argument,
+        wrong-import-order,
+        xrange-builtin,
+        zip-builtin-not-iterating,
+
+
+[REPORTS]
+
+# Set the output format. Available formats are text, parseable, colorized, msvs
+# (visual studio) and html. You can also give a reporter class, eg
+# mypackage.mymodule.MyReporterClass.
+output-format=text
+
+# Tells whether to display a full report or only the messages
+reports=no
+
+# Python expression which should return a note less than 10 (10 is the highest
+# note). You have access to the variables errors warning, statement which
+# respectively contain the number of errors / warnings messages and the total
+# number of statements analyzed. This is used by the global evaluation report
+# (RP0004).
+evaluation=10.0 - ((float(5 * error + warning + refactor + convention) / statement) * 10)
+
+# Template used to display messages. This is a python new-style format string
+# used to format the message information. See doc for all details
+#msg-template=
+
+
+[BASIC]
+
+# Good variable names which should always be accepted, separated by a comma
+good-names=main,_
+
+# Bad variable names which should always be refused, separated by a comma
+bad-names=
+
+# Colon-delimited sets of names that determine each other's naming style when
+# the name regexes allow several styles.
+name-group=
+
+# Include a hint for the correct naming format with invalid-name
+include-naming-hint=no
+
+# List of decorators that produce properties, such as abc.abstractproperty. Add
+# to this list to register other decorators that produce valid properties.
+property-classes=abc.abstractproperty,cached_property.cached_property,cached_property.threaded_cached_property,cached_property.cached_property_with_ttl,cached_property.threaded_cached_property_with_ttl
+
+# Regular expression matching correct function names
+function-rgx=^(?:(?P<exempt>setUp|tearDown|setUpModule|tearDownModule)|(?P<camel_case>_?[A-Z][a-zA-Z0-9]*)|(?P<snake_case>_?[a-z][a-z0-9_]*))$
+
+# Regular expression matching correct variable names
+variable-rgx=^[a-z][a-z0-9_]*$
+
+# Regular expression matching correct constant names
+const-rgx=^(_?[A-Z][A-Z0-9_]*|__[a-z0-9_]+__|_?[a-z][a-z0-9_]*)$
+
+# Regular expression matching correct attribute names
+attr-rgx=^_{0,2}[a-z][a-z0-9_]*$
+
+# Regular expression matching correct argument names
+argument-rgx=^[a-z][a-z0-9_]*$
+
+# Regular expression matching correct class attribute names
+class-attribute-rgx=^(_?[A-Z][A-Z0-9_]*|__[a-z0-9_]+__|_?[a-z][a-z0-9_]*)$
+
+# Regular expression matching correct inline iteration names
+inlinevar-rgx=^[a-z][a-z0-9_]*$
+
+# Regular expression matching correct class names
+class-rgx=^_?[A-Z][a-zA-Z0-9]*$
+
+# Regular expression matching correct module names
+module-rgx=^(_?[a-z][a-z0-9_]*|__init__)$
+
+# Regular expression matching correct method names
+method-rgx=(?x)^(?:(?P<exempt>_[a-z0-9_]+__|runTest|setUp|tearDown|setUpTestCase|tearDownTestCase|setupSelf|tearDownClass|setUpClass|(test|assert)_*[A-Z0-9][a-zA-Z0-9_]*|next)|(?P<camel_case>_{0,2}[A-Z][a-zA-Z0-9_]*)|(?P<snake_case>_{0,2}[a-z][a-z0-9_]*))$
+
+# Regular expression which should only match function or class names that do
+# not require a docstring.
+no-docstring-rgx=(__.*__|main|test.*|.*test|.*Test)$
+
+# Minimum line length for functions/classes that require docstrings, shorter
+# ones are exempt.
+docstring-min-length=12
+
+
+[TYPECHECK]
+
+# List of decorators that produce context managers, such as
+# contextlib.contextmanager. Add to this list to register other decorators that
+# produce valid context managers.
+contextmanager-decorators=contextlib.contextmanager,contextlib2.contextmanager
+
+# List of module names for which member attributes should not be checked
+# (useful for modules/projects where namespaces are manipulated during runtime
+# and thus existing member attributes cannot be deduced by static analysis. It
+# supports qualified module names, as well as Unix pattern matching.
+ignored-modules=
+
+# List of class names for which member attributes should not be checked (useful
+# for classes with dynamically set attributes). This supports the use of
+# qualified names.
+ignored-classes=optparse.Values,thread._local,_thread._local
+
+# List of members which are set dynamically and missed by pylint inference
+# system, and so shouldn't trigger E1101 when accessed. Python regular
+# expressions are accepted.
+generated-members=
+
+
+[FORMAT]
+
+# Maximum number of characters on a single line.
+max-line-length=80
+
+# TODO(https://github.com/pylint-dev/pylint/issues/3352): Direct pylint to exempt
+# lines made too long by directives to pytype.
+
+# Regexp for a line that is allowed to be longer than the limit.
+ignore-long-lines=(?x)(
+  ^\s*(\#\ )?<?https?://\S+>?$|
+  ^\s*(from\s+\S+\s+)?import\s+.+$)
+
+# Allow the body of an if to be on the same line as the test if there is no
+# else.
+single-line-if-stmt=yes
+
+# Maximum number of lines in a module
+max-module-lines=99999
+
+# String used as indentation unit.  The internal Google style guide mandates 2
+# spaces.  Google's externaly-published style guide says 4, consistent with
+# PEP 8.  Here, we use 2 spaces, for conformity with many open-sourced Google
+# projects (like TensorFlow).
+indent-string='  '
+
+# Number of spaces of indent required inside a hanging  or continued line.
+indent-after-paren=4
+
+# Expected format of line ending, e.g. empty (any line ending), LF or CRLF.
+expected-line-ending-format=
+
+
+[MISCELLANEOUS]
+
+# List of note tags to take in consideration, separated by a comma.
+notes=TODO
+
+
+[STRING]
+
+# This flag controls whether inconsistent-quotes generates a warning when the
+# character used as a quote delimiter is used inconsistently within a module.
+check-quote-consistency=yes
+
+
+[VARIABLES]
+
+# Tells whether we should check for unused import in __init__ files.
+init-import=no
+
+# A regular expression matching the name of dummy variables (i.e. expectedly
+# not used).
+dummy-variables-rgx=^\*{0,2}(_$|unused_|dummy_)
+
+# List of additional names supposed to be defined in builtins. Remember that
+# you should avoid to define new builtins when possible.
+additional-builtins=
+
+# List of strings which can identify a callback function by name. A callback
+# name must start or end with one of those strings.
+callbacks=cb_,_cb
+
+# List of qualified module names which can have objects that can redefine
+# builtins.
+redefining-builtins-modules=six,six.moves,past.builtins,future.builtins,functools
+
+
+[LOGGING]
+
+# Logging modules to check that the string format arguments are in logging
+# function parameter format
+logging-modules=logging,absl.logging,tensorflow.io.logging
+
+
+[SIMILARITIES]
+
+# Minimum lines number of a similarity.
+min-similarity-lines=4
+
+# Ignore comments when computing similarities.
+ignore-comments=yes
+
+# Ignore docstrings when computing similarities.
+ignore-docstrings=yes
+
+# Ignore imports when computing similarities.
+ignore-imports=no
+
+
+[SPELLING]
+
+# Spelling dictionary name. Available dictionaries: none. To make it working
+# install python-enchant package.
+spelling-dict=
+
+# List of comma separated words that should not be checked.
+spelling-ignore-words=
+
+# A path to a file that contains private dictionary; one word per line.
+spelling-private-dict-file=
+
+# Tells whether to store unknown words to indicated private dictionary in
+# --spelling-private-dict-file option instead of raising a message.
+spelling-store-unknown-words=no
+
+
+[IMPORTS]
+
+# Deprecated modules which should not be used, separated by a comma
+deprecated-modules=regsub,
+                   TERMIOS,
+                   Bastion,
+                   rexec,
+                   sets
+
+# Create a graph of every (i.e. internal and external) dependencies in the
+# given file (report RP0402 must not be disabled)
+import-graph=
+
+# Create a graph of external dependencies in the given file (report RP0402 must
+# not be disabled)
+ext-import-graph=
+
+# Create a graph of internal dependencies in the given file (report RP0402 must
+# not be disabled)
+int-import-graph=
+
+# Force import order to recognize a module as part of the standard
+# compatibility libraries.
+known-standard-library=
+
+# Force import order to recognize a module as part of a third party library.
+known-third-party=enchant, absl
+
+# Analyse import fallback blocks. This can be used to support both Python 2 and
+# 3 compatible code, which means that the block might have code that exists
+# only in one or another interpreter, leading to false positives when analysed.
+analyse-fallback-blocks=no
+
+
+[CLASSES]
+
+# List of method names used to declare (i.e. assign) instance attributes.
+defining-attr-methods=__init__,
+                      __new__,
+                      setUp
+
+# List of member names, which should be excluded from the protected access
+# warning.
+exclude-protected=_asdict,
+                  _fields,
+                  _replace,
+                  _source,
+                  _make
+
+# List of valid names for the first argument in a class method.
+valid-classmethod-first-arg=cls,
+                            class_
+
+# List of valid names for the first argument in a metaclass class method.
+valid-metaclass-classmethod-first-arg=mcs
",No,OTHER
adk-python,src/google/adk/tools/google_api_tool/google_api_tool_set.py,src/google/adk/tools/google_api_tool/google_api_tool_set.py,6a04ff84bac7c8f79e94b84daabfb6f39154b00c,27b229719e6622de89dcaf65053734f249e23c06,adapt google api toolset and api hub toolset to new toolset interface  PiperOrigin-RevId: 757946541,"diff --git a/src/google/adk/tools/google_api_tool/google_api_tool_set.py b/src/google/adk/tools/google_api_tool/google_api_tool_set.py
index 5409593..7707106 100644
--- a/src/google/adk/tools/google_api_tool/google_api_tool_set.py
+++ b/src/google/adk/tools/google_api_tool/google_api_tool_set.py
@@ -17,37 +17,67 @@ from __future__ import annotations
 import inspect
 import os
 from typing import Any
-from typing import Final
 from typing import List
 from typing import Optional
+from typing import override
 from typing import Type
+from typing import Union
 
+from ...agents.readonly_context import ReadonlyContext
 from ...auth import OpenIdConnectWithConfig
+from ...tools.base_toolset import BaseToolset
+from ...tools.base_toolset import ToolPredicate
 from ..openapi_tool import OpenAPIToolset
-from ..openapi_tool import RestApiTool
 from .google_api_tool import GoogleApiTool
 from .googleapi_to_openapi_converter import GoogleApiToOpenApiConverter
 
 
-class GoogleApiToolSet:
-  """"""Google API Tool Set.""""""
+class GoogleApiToolset(BaseToolset):
+  """"""Google API Toolset contains tools for interacting with Google APIs.
 
-  def __init__(self, tools: List[RestApiTool]):
-    self.tools: Final[List[GoogleApiTool]] = [
-        GoogleApiTool(tool) for tool in tools
-    ]
+  Usually one toolsets will contains tools only replated to one Google API, e.g.
+  Google Bigquery API toolset will contains tools only related to Google
+  Bigquery API, like list dataset tool, list table tool etc.
+  """"""
 
-  def get_tools(self) -> List[GoogleApiTool]:
+  def __init__(
+      self,
+      openapi_toolset: OpenAPIToolset,
+      client_id: Optional[str] = None,
+      client_secret: Optional[str] = None,
+      tool_filter: Optional[Union[ToolPredicate, List[str]]] = None,
+  ):
+    self.openapi_toolset = openapi_toolset
+    self.tool_filter = tool_filter
+    self.client_id = client_id
+    self.client_secret = client_secret
+
+  @override
+  async def get_tools(
+      self, readonly_context: Optional[ReadonlyContext] = None
+  ) -> List[GoogleApiTool]:
     """"""Get all tools in the toolset.""""""
-    return self.tools
+    tools = []
+
+    for tool in await self.openapi_toolset.get_tools(readonly_context):
+      if self.tool_filter and (
+          isinstance(self.tool_filter, ToolPredicate)
+          and not self.tool_filter(tool, readonly_context)
+          or isinstance(self.tool_filter, list)
+          and tool.name not in self.tool_filter
+      ):
+        continue
+      google_api_tool = GoogleApiTool(tool)
+      google_api_tool.configure_auth(self.client_id, self.client_secret)
+      tools.append(google_api_tool)
 
-  def get_tool(self, tool_name: str) -> Optional[GoogleApiTool]:
-    """"""Get a tool by name.""""""
-    matching_tool = filter(lambda t: t.name == tool_name, self.tools)
-    return next(matching_tool, None)
+    return tools
+
+  def set_tool_filter(self, tool_filter: Union[ToolPredicate, List[str]]):
+    self.tool_filter = tool_filter
 
   @staticmethod
-  def _load_tool_set_with_oidc_auth(
+  def _load_toolset_with_oidc_auth(
       spec_file: Optional[str] = None,
       spec_dict: Optional[dict[str, Any]] = None,
       scopes: Optional[list[str]] = None,
@@ -64,7 +94,7 @@ class GoogleApiToolSet:
       yaml_path = os.path.join(caller_dir, spec_file)
       with open(yaml_path, 'r', encoding='utf-8') as file:
         spec_str = file.read()
-    tool_set = OpenAPIToolset(
+    toolset = OpenAPIToolset(
         spec_dict=spec_dict,
         spec_str=spec_str,
         spec_str_type='yaml',
@@ -85,18 +115,18 @@ class GoogleApiToolSet:
             scopes=scopes,
         ),
     )
-    return tool_set
+    return toolset
 
   def configure_auth(self, client_id: str, client_secret: str):
-    for tool in self.tools:
-      tool.configure_auth(client_id, client_secret)
+    self.client_id = client_id
+    self.client_secret = client_secret
 
   @classmethod
-  def load_tool_set(
-      cls: Type[GoogleApiToolSet],
+  def load_toolset(
+      cls: Type[GoogleApiToolset],
       api_name: str,
       api_version: str,
-  ) -> GoogleApiToolSet:
+  ) -> GoogleApiToolset:
     spec_dict = GoogleApiToOpenApiConverter(api_name, api_version).convert()
     scope = list(
         spec_dict['components']['securitySchemes']['oauth2']['flows'][
@@ -104,7 +134,10 @@ class GoogleApiToolSet:
         ]['scopes'].keys()
     )[0]
     return cls(
-        cls._load_tool_set_with_oidc_auth(
-            spec_dict=spec_dict, scopes=[scope]
-        ).get_tools()
+        cls._load_toolset_with_oidc_auth(spec_dict=spec_dict, scopes=[scope])
     )
+
+  @override
+  async def close(self):
+    if self.openapi_toolset:
+      await self.openapi_toolset.close()
","diff --git a/src/google/adk/tools/google_api_tool/google_api_tool_set.py b/src/google/adk/tools/google_api_tool/google_api_tool_set.py
index 5409593..7707106 100644
--- a/src/google/adk/tools/google_api_tool/google_api_tool_set.py
+++ b/src/google/adk/tools/google_api_tool/google_api_tool_set.py
@@ -17,37 +17,67 @@ from __future__ import annotations
 import inspect
 import os
 from typing import Any
-from typing import Final
 from typing import List
 from typing import Optional
+from typing import override
 from typing import Type
+from typing import Union
 
+from ...agents.readonly_context import ReadonlyContext
 from ...auth import OpenIdConnectWithConfig
+from ...tools.base_toolset import BaseToolset
+from ...tools.base_toolset import ToolPredicate
 from ..openapi_tool import OpenAPIToolset
-from ..openapi_tool import RestApiTool
 from .google_api_tool import GoogleApiTool
 from .googleapi_to_openapi_converter import GoogleApiToOpenApiConverter
 
 
-class GoogleApiToolSet:
-  """"""Google API Tool Set.""""""
+class GoogleApiToolset(BaseToolset):
+  """"""Google API Toolset contains tools for interacting with Google APIs.
 
-  def __init__(self, tools: List[RestApiTool]):
-    self.tools: Final[List[GoogleApiTool]] = [
-        GoogleApiTool(tool) for tool in tools
-    ]
+  Usually one toolsets will contains tools only replated to one Google API, e.g.
+  Google Bigquery API toolset will contains tools only related to Google
+  Bigquery API, like list dataset tool, list table tool etc.
+  """"""
 
-  def get_tools(self) -> List[GoogleApiTool]:
+  def __init__(
+      self,
+      openapi_toolset: OpenAPIToolset,
+      client_id: Optional[str] = None,
+      client_secret: Optional[str] = None,
+      tool_filter: Optional[Union[ToolPredicate, List[str]]] = None,
+  ):
+    self.openapi_toolset = openapi_toolset
+    self.tool_filter = tool_filter
+    self.client_id = client_id
+    self.client_secret = client_secret
+
+  @override
+  async def get_tools(
+      self, readonly_context: Optional[ReadonlyContext] = None
+  ) -> List[GoogleApiTool]:
     """"""Get all tools in the toolset.""""""
-    return self.tools
+    tools = []
 
-  def get_tool(self, tool_name: str) -> Optional[GoogleApiTool]:
-    """"""Get a tool by name.""""""
-    matching_tool = filter(lambda t: t.name == tool_name, self.tools)
-    return next(matching_tool, None)
+    for tool in await self.openapi_toolset.get_tools(readonly_context):
+      if self.tool_filter and (
+          isinstance(self.tool_filter, ToolPredicate)
+          and not self.tool_filter(tool, readonly_context)
+          or isinstance(self.tool_filter, list)
+          and tool.name not in self.tool_filter
+      ):
+        continue
+      google_api_tool = GoogleApiTool(tool)
+      google_api_tool.configure_auth(self.client_id, self.client_secret)
+      tools.append(google_api_tool)
+
+    return tools
+
+  def set_tool_filter(self, tool_filter: Union[ToolPredicate, List[str]]):
+    self.tool_filter = tool_filter
 
   @staticmethod
-  def _load_tool_set_with_oidc_auth(
+  def _load_toolset_with_oidc_auth(
       spec_file: Optional[str] = None,
       spec_dict: Optional[dict[str, Any]] = None,
       scopes: Optional[list[str]] = None,
@@ -64,7 +94,7 @@ class GoogleApiToolSet:
       yaml_path = os.path.join(caller_dir, spec_file)
       with open(yaml_path, 'r', encoding='utf-8') as file:
         spec_str = file.read()
-    tool_set = OpenAPIToolset(
+    toolset = OpenAPIToolset(
         spec_dict=spec_dict,
         spec_str=spec_str,
         spec_str_type='yaml',
@@ -85,18 +115,18 @@ class GoogleApiToolSet:
             scopes=scopes,
         ),
     )
-    return tool_set
+    return toolset
 
   def configure_auth(self, client_id: str, client_secret: str):
-    for tool in self.tools:
-      tool.configure_auth(client_id, client_secret)
+    self.client_id = client_id
+    self.client_secret = client_secret
 
   @classmethod
-  def load_tool_set(
-      cls: Type[GoogleApiToolSet],
+  def load_toolset(
+      cls: Type[GoogleApiToolset],
       api_name: str,
       api_version: str,
-  ) -> GoogleApiToolSet:
+  ) -> GoogleApiToolset:
     spec_dict = GoogleApiToOpenApiConverter(api_name, api_version).convert()
     scope = list(
         spec_dict['components']['securitySchemes']['oauth2']['flows'][
@@ -104,7 +134,10 @@ class GoogleApiToolSet:
         ]['scopes'].keys()
     )[0]
     return cls(
-        cls._load_tool_set_with_oidc_auth(
-            spec_dict=spec_dict, scopes=[scope]
-        ).get_tools()
+        cls._load_toolset_with_oidc_auth(spec_dict=spec_dict, scopes=[scope])
     )
+
+  @override
+  async def close(self):
+    if self.openapi_toolset:
+      await self.openapi_toolset.close()
",Yes,SOURCE
